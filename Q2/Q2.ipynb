{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import sklearn\n",
    "\n",
    "EPSILON = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (745, 3)\n",
      "Test set shape: (745, 3)\n",
      "{'business': 0, 'entertainment': 1, 'politics': 2, 'sport': 3, 'tech': 4}\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv('data/train.csv')\n",
    "train_df, test_df = sklearn.model_selection.train_test_split(data_df, test_size=0.5, random_state=42)\n",
    "print(f'Train set shape: {train_df.shape}')\n",
    "print(f'Test set shape: {test_df.shape}')\n",
    "\n",
    "labels_unq = np.unique(train_df['Category'])\n",
    "labels_map = {category: idx for idx, category in enumerate(labels_unq)}\n",
    "print(labels_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower(df):\n",
    "    df = df.copy()\n",
    "    df['Text'] = df['Text'].apply(lambda x: x.lower())\n",
    "    return df\n",
    "\n",
    "def remove_punctuations(df):\n",
    "    df = df.copy()\n",
    "    df['Text'] = df['Text'].apply(lambda x: ''.join([char for char in x if char not in string.punctuation]))\n",
    "    return df\n",
    "\n",
    "def tokenize(df):\n",
    "    df = df.copy()\n",
    "    df['tokens'] = df['Text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "    return df\n",
    "\n",
    "def filter_stopwords(df):\n",
    "    df = df.copy()\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    df['tokens'] = df['tokens'].apply(lambda x: [word for word in x if word not in stopwords])\n",
    "    return df\n",
    "\n",
    "def stem(df):\n",
    "    df = df.copy()\n",
    "    porter = nltk.stem.porter.PorterStemmer()\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    df['tokens'] = df['tokens'].apply(lambda x: [porter.stem(word) for word in x])\n",
    "    return df\n",
    "\n",
    "def preprocess(df):\n",
    "    return stem(filter_stopwords(tokenize(remove_punctuations(lower(df)))))\n",
    "\n",
    "train_df_preprocessed = preprocess(train_df)\n",
    "test_df_preprocessed = preprocess(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size = 14306\n"
     ]
    }
   ],
   "source": [
    "def get_vocab(df):\n",
    "    unique_words = list(set(df['tokens'].sum()))\n",
    "    vocab2idx = {word: idx for idx, word in enumerate(unique_words)}\n",
    "    idx2vocab = {idx: word for idx, word in enumerate(unique_words)}\n",
    "    print(f'Vocabulary size = {len(unique_words)}')\n",
    "\n",
    "    return vocab2idx, idx2vocab\n",
    "\n",
    "vocab2idx, idx2vocab = get_vocab(train_df_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_mat(df, vocab2idx):\n",
    "    tf_mat = np.zeros((len(labels_map), len(vocab2idx)), dtype=np.int32)\n",
    "    for category, label in labels_map.items():\n",
    "        df_category = df[df['Category'] == category]\n",
    "        terms = list(df_category['tokens'].sum())\n",
    "        for term in terms:\n",
    "            tf_mat[label, vocab2idx[term]] += 1\n",
    "    return tf_mat\n",
    "\n",
    "def get_icf_mat(tf_mat):\n",
    "    term_presence_mat = np.where(tf_mat > 0, 1, 0)\n",
    "    cf_mat = np.sum(term_presence_mat, axis=0, keepdims=True)\n",
    "    icf_mat = np.log10(tf_mat.shape[0] / cf_mat)\n",
    "    \n",
    "    return icf_mat\n",
    "\n",
    "def get_tf_icf_mat(tf_mat, icf_mat):\n",
    "    return tf_mat * icf_mat\n",
    "\n",
    "tf_mat = get_tf_mat(train_df_preprocessed, vocab2idx)\n",
    "icf_mat = get_icf_mat(tf_mat)\n",
    "tf_icf_mat = get_tf_icf_mat(tf_mat, icf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probabilities_mat(df, tf_mat):\n",
    "    denominator = np.sum(tf_mat, axis=1, keepdims=True)\n",
    "    prob_mat = tf_mat / denominator\n",
    "\n",
    "    categories, category_counts = np.unique(df['Category'], return_counts=True)\n",
    "    class_prob_mat = np.zeros((5,))\n",
    "    for idx, category in enumerate(categories):\n",
    "        class_prob_mat[labels_map[category]] = category_counts[idx] / np.sum(category_counts)\n",
    "\n",
    "    return prob_mat, class_prob_mat\n",
    "\n",
    "prob_mat, class_prob_mat = get_probabilities_mat(train_df_preprocessed, tf_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference(df, tf_icf_mat, prob_mat, class_prob_mat, vocab2idx):\n",
    "    df = df.copy()\n",
    "    df['tokens'] = df['tokens'].apply(lambda x: [word for word in x if word in vocab2idx])\n",
    "    \n",
    "    def infer(tokens):\n",
    "        probs = []\n",
    "        for category, label in labels_map.items():\n",
    "            class_prob = np.log(class_prob_mat[label])\n",
    "            post_prob = 0\n",
    "            for term in tokens:\n",
    "                post_prob += np.log(prob_mat[label, vocab2idx[term]] * tf_icf_mat[label, vocab2idx[term]] + EPSILON)\n",
    "            \n",
    "            probs.append(class_prob + post_prob)\n",
    "        return np.argmax(probs)\n",
    "            \n",
    "    \n",
    "    df['prediction'] = df['tokens'].apply(infer)\n",
    "    return df\n",
    "\n",
    "test_df_pred = get_inference(test_df_preprocessed, tf_icf_mat, prob_mat, class_prob_mat, vocab2idx)\n",
    "train_df_pred = get_inference(train_df_preprocessed, tf_icf_mat, prob_mat, class_prob_mat, vocab2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(df):\n",
    "    y_true = [labels_map[category] for category in df['Category']]\n",
    "    y_pred = df['prediction'].tolist()\n",
    "    report = sklearn.metrics.classification_report(y_true, y_pred)\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_report = get_metrics(train_df_pred)\n",
    "test_report = get_metrics(test_df_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       165\n",
      "           1       0.99      1.00      1.00       143\n",
      "           2       1.00      1.00      1.00       132\n",
      "           3       1.00      0.99      1.00       182\n",
      "           4       1.00      0.99      1.00       123\n",
      "\n",
      "    accuracy                           1.00       745\n",
      "   macro avg       1.00      1.00      1.00       745\n",
      "weighted avg       1.00      1.00      1.00       745\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       171\n",
      "           1       0.98      0.98      0.98       130\n",
      "           2       0.98      0.96      0.97       142\n",
      "           3       0.99      1.00      1.00       164\n",
      "           4       0.95      0.99      0.97       138\n",
      "\n",
      "    accuracy                           0.98       745\n",
      "   macro avg       0.98      0.98      0.98       745\n",
      "weighted avg       0.98      0.98      0.98       745\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(test_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computer_vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
