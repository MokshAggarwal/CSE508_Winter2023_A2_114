{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0fe432c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: contractions in /home/parth20/.local/lib/python3.10/site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /home/parth20/.local/lib/python3.10/site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: pyahocorasick in /home/parth20/.local/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n",
      "Requirement already satisfied: anyascii in /home/parth20/.local/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/parth20/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "!pip install contractions\n",
    "import contractions\n",
    "import pickle\n",
    "nltk.download('stopwords')\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692b0ee3",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52bc8093",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1400/1400 [00:00<00:00, 1933495.42it/s]\n",
      "100%|██████████| 1400/1400 [00:00<00:00, 43821.74it/s]\n"
     ]
    }
   ],
   "source": [
    "path = \"CSE508_Winter2023_Dataset\"\n",
    "dir_ = os.listdir(path)\n",
    "doc_id_to_name = {}  # Mapping doc_id numbers to the documents names\n",
    "file_data = {}  # Document data according to document name\n",
    "\n",
    "for i in tqdm(range(len(dir_))):\n",
    "    doc_id_to_name[i] = dir_[i]\n",
    "\n",
    "for i in tqdm(range(len(dir_))):\n",
    "    with open(f'{path}/{dir_[i]}') as f:\n",
    "        contents = f.read()\n",
    "        file_data[dir_[i]] = contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a75f0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cranfield1111'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_id_to_name[34]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80d7690",
   "metadata": {},
   "source": [
    "# Extracting Relevant Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eebcfda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "req_text = {}  # Required data between these mentioned tags\n",
    "\n",
    "for key in file_data.keys():\n",
    "    text = file_data[key]\n",
    "    \n",
    "    soup = BeautifulSoup(text, 'html.parser')  # Creating soup object and passing it the text file\n",
    "    title_tag = soup.find('title')  # Searching for TITLE tag in the document\n",
    "    text_tag = soup.find('text')  # Searching for TEXT tag in the document\n",
    "    \n",
    "    title_data = \"\"\n",
    "    text_data = \"\"\n",
    "    \n",
    "    if title_tag:\n",
    "        title_data = title_tag.text  # If TITLE tag is found updating the title data otherwise it is empty\n",
    "    \n",
    "    if text_tag:\n",
    "        text_data = text_tag.text  # If TEXT tag is found updating the text data otherwise it is empty\n",
    "        \n",
    "    new_text = f'{title_data} {text_data}'  # Concatenating the data with a blank space\n",
    "    \n",
    "    req_text[key] = new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d771e7",
   "metadata": {},
   "source": [
    "**Printing for first 5 files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "906b28c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before !-------------------!\n",
      "\n",
      "<DOC>\n",
      "<DOCNO>\n",
      "731\n",
      "</DOCNO>\n",
      "<TITLE>\n",
      "upper and lower bounds for the solution of the first\n",
      "biharmonic boundary value problem .\n",
      "</TITLE>\n",
      "<AUTHOR>\n",
      "diaz,g.b., and greenberg,h.g.\n",
      "</AUTHOR>\n",
      "<BIBLIO>\n",
      "j. math. phys. 27, 1948, 193.\n",
      "</BIBLIO>\n",
      "<TEXT>\n",
      "  let w(x,y) be a solution of the boundary value problem\n",
      "where r is a plane\n",
      "domain with the boundary c .  the authors obtain upper and\n",
      "lower bounds for, the value of w at a point in r,\n",
      "by a method which is applicable to many other problems .\n",
      "  if u is a function satisfying the boundary conditions\n",
      "and v is a function satisfying the partial differential equation,\n",
      "then the authors obtain by applying green's classical\n",
      "identity and schwarz's inequality a pair of inequalities\n",
      "of the form where .\n",
      "  together with the function w the authors consider a\n",
      "function the solution of the boundary value problem\n",
      "on c, and in\n",
      "analogy with the functions u and v associated with the function\n",
      "w a pair of functions and associated with the function\n",
      ".  in the expression for derived from green's\n",
      "classical identity appears an unknown line integral containing\n",
      "the values of w and on c .  but the same line\n",
      "integral appears also in the expressions for\n",
      "to which the above inequalities are\n",
      "applicable .\n",
      "  in this way the authors obtain two inequalities of the form\n",
      "where b and b', respectively, are approximate\n",
      "values of .  in order to improve these bounds\n",
      "one may add to u a linear set of functions and to v a\n",
      "linear set of functions and then minimize h(u-v) in order\n",
      "to determine the coefficients of the best linear combinations .\n",
      "if the sequences and are complete in a certain sense\n",
      "defined by the authors the approximations will converge to\n",
      "the value .\n",
      "</TEXT>\n",
      "</DOC>\n",
      "\n",
      "\n",
      "After  !-------------------!\n",
      "\n",
      "\n",
      "upper and lower bounds for the solution of the first\n",
      "biharmonic boundary value problem .\n",
      " \n",
      "  let w(x,y) be a solution of the boundary value problem\n",
      "where r is a plane\n",
      "domain with the boundary c .  the authors obtain upper and\n",
      "lower bounds for, the value of w at a point in r,\n",
      "by a method which is applicable to many other problems .\n",
      "  if u is a function satisfying the boundary conditions\n",
      "and v is a function satisfying the partial differential equation,\n",
      "then the authors obtain by applying green's classical\n",
      "identity and schwarz's inequality a pair of inequalities\n",
      "of the form where .\n",
      "  together with the function w the authors consider a\n",
      "function the solution of the boundary value problem\n",
      "on c, and in\n",
      "analogy with the functions u and v associated with the function\n",
      "w a pair of functions and associated with the function\n",
      ".  in the expression for derived from green's\n",
      "classical identity appears an unknown line integral containing\n",
      "the values of w and on c .  but the same line\n",
      "integral appears also in the expressions for\n",
      "to which the above inequalities are\n",
      "applicable .\n",
      "  in this way the authors obtain two inequalities of the form\n",
      "where b and b', respectively, are approximate\n",
      "values of .  in order to improve these bounds\n",
      "one may add to u a linear set of functions and to v a\n",
      "linear set of functions and then minimize h(u-v) in order\n",
      "to determine the coefficients of the best linear combinations .\n",
      "if the sequences and are complete in a certain sense\n",
      "defined by the authors the approximations will converge to\n",
      "the value .\n",
      "\n",
      "\n",
      "Before !-------------------!\n",
      "\n",
      "<DOC>\n",
      "<DOCNO>\n",
      "1342\n",
      "</DOCNO>\n",
      "<TITLE>\n",
      "the calculation of aerodynamic loading on surfaces of any shape .\n",
      "</TITLE>\n",
      "<AUTHOR>\n",
      "falkner, v.m.\n",
      "</AUTHOR>\n",
      "<BIBLIO>\n",
      "r + m 1910, august 1943 .\n",
      "</BIBLIO>\n",
      "<TEXT>\n",
      "the object of the report is to establish a routine method for the calculation\n",
      "of aerodynamic loads on wings of arbitrary shape . the method\n",
      "developed is based on potential theory and uses a general mathematical\n",
      "formula for continuous loading on a wing which is equivalent to a double\n",
      " fourier series with unknown coefficients . in order to evaluate the\n",
      "unknown coefficients the continuous loading is split up into a regular\n",
      "pattern of horseshoe vortices, the strengths of which are proportional\n",
      "to the unknown coefficients and to standard factors which are given in a\n",
      " table . the total downwash at chosen pivotal points is obtained by\n",
      "summing the downwashes due to the individual vortices, a process which\n",
      "is simplified by the use of specially prepared tables of the properties\n",
      "of the horseshoe vortex . by equating the downwash to the slope of the\n",
      "wing at each pivotal point, simultaneous equations are obtained, the\n",
      "solution of which defines the unknown coefficients .\n",
      "the first layout involves a total of 76 vortices over the wing, and a\n",
      "second layout, involving a total of 84, is shown to be of superior\n",
      "accuracy . the effect on the solution of the number of pivotal points is\n",
      " investigated and it is concluded that by a suitable choice, it is unnecessary\n",
      "to use a large number . results for a rectangular wing at\n",
      "with those obtained by other workers and it appears that there may be\n",
      "errors in published results in at least one of these cases . immediate\n",
      "development includes the application to the calculation of the characteristics\n",
      "of actual sweptback wings, including rotary derivatives, and\n",
      " future development includes also applications in wind tunnel design and\n",
      " technique .\n",
      "</TEXT>\n",
      "</DOC>\n",
      "\n",
      "\n",
      "After  !-------------------!\n",
      "\n",
      "\n",
      "the calculation of aerodynamic loading on surfaces of any shape .\n",
      " \n",
      "the object of the report is to establish a routine method for the calculation\n",
      "of aerodynamic loads on wings of arbitrary shape . the method\n",
      "developed is based on potential theory and uses a general mathematical\n",
      "formula for continuous loading on a wing which is equivalent to a double\n",
      " fourier series with unknown coefficients . in order to evaluate the\n",
      "unknown coefficients the continuous loading is split up into a regular\n",
      "pattern of horseshoe vortices, the strengths of which are proportional\n",
      "to the unknown coefficients and to standard factors which are given in a\n",
      " table . the total downwash at chosen pivotal points is obtained by\n",
      "summing the downwashes due to the individual vortices, a process which\n",
      "is simplified by the use of specially prepared tables of the properties\n",
      "of the horseshoe vortex . by equating the downwash to the slope of the\n",
      "wing at each pivotal point, simultaneous equations are obtained, the\n",
      "solution of which defines the unknown coefficients .\n",
      "the first layout involves a total of 76 vortices over the wing, and a\n",
      "second layout, involving a total of 84, is shown to be of superior\n",
      "accuracy . the effect on the solution of the number of pivotal points is\n",
      " investigated and it is concluded that by a suitable choice, it is unnecessary\n",
      "to use a large number . results for a rectangular wing at\n",
      "with those obtained by other workers and it appears that there may be\n",
      "errors in published results in at least one of these cases . immediate\n",
      "development includes the application to the calculation of the characteristics\n",
      "of actual sweptback wings, including rotary derivatives, and\n",
      " future development includes also applications in wind tunnel design and\n",
      " technique .\n",
      "\n",
      "\n",
      "Before !-------------------!\n",
      "\n",
      "<DOC>\n",
      "<DOCNO>\n",
      "1385\n",
      "</DOCNO>\n",
      "<TITLE>\n",
      "air flow in a separating laminar boundary layer .\n",
      "</TITLE>\n",
      "<AUTHOR>\n",
      "schubauer,g.b.\n",
      "</AUTHOR>\n",
      "<BIBLIO>\n",
      "naca r.527, 1935.\n",
      "</BIBLIO>\n",
      "<TEXT>\n",
      "  the speed distribution in a laminar boundary layer on\n",
      "the surface of an elliptic cylinder, of major and minor\n",
      "axes 11.78 and 3.98 inches, respectively, has been determined\n",
      "by means of a hot-wire anemometer .  the direction\n",
      "of the impinging air stream was parallel to the major axis .\n",
      "special attention was given to the speed distribution in\n",
      "the region of separation and to the exact location of the\n",
      "point of separation .  an approximate method, developed\n",
      "by k. pohlhausen for computing the speed distribution,\n",
      "the thickness of the layer, and the point of separation, is\n",
      "described in detail,. and speed-distribution curves calculated\n",
      "by this method are presented for comparison with\n",
      "experiment .  good agreement is obtained along the forward\n",
      "part of the cylinder, but pohlhausen's method fails\n",
      "shortly before the separation point is reached and consequently\n",
      "cannot be used to locate this point .\n",
      "  the work was carried out at the national bureau of\n",
      "standards with the cooperation and financial assistance\n",
      "of the national advisory committee for aeronautics .\n",
      "</TEXT>\n",
      "</DOC>\n",
      "\n",
      "\n",
      "After  !-------------------!\n",
      "\n",
      "\n",
      "air flow in a separating laminar boundary layer .\n",
      " \n",
      "  the speed distribution in a laminar boundary layer on\n",
      "the surface of an elliptic cylinder, of major and minor\n",
      "axes 11.78 and 3.98 inches, respectively, has been determined\n",
      "by means of a hot-wire anemometer .  the direction\n",
      "of the impinging air stream was parallel to the major axis .\n",
      "special attention was given to the speed distribution in\n",
      "the region of separation and to the exact location of the\n",
      "point of separation .  an approximate method, developed\n",
      "by k. pohlhausen for computing the speed distribution,\n",
      "the thickness of the layer, and the point of separation, is\n",
      "described in detail,. and speed-distribution curves calculated\n",
      "by this method are presented for comparison with\n",
      "experiment .  good agreement is obtained along the forward\n",
      "part of the cylinder, but pohlhausen's method fails\n",
      "shortly before the separation point is reached and consequently\n",
      "cannot be used to locate this point .\n",
      "  the work was carried out at the national bureau of\n",
      "standards with the cooperation and financial assistance\n",
      "of the national advisory committee for aeronautics .\n",
      "\n",
      "\n",
      "Before !-------------------!\n",
      "\n",
      "<DOC>\n",
      "<DOCNO>\n",
      "413\n",
      "</DOCNO>\n",
      "<TITLE>\n",
      "turbulent skin friction at high mach numbers and reynolds\n",
      "numbers in air and helium . nasa r82, 1960 .\n",
      "</TITLE>\n",
      "<AUTHOR>\n",
      "matting,f.w., chapman,d.r., nyholm,j.r. and thomas,a.g.\n",
      "</AUTHOR>\n",
      "<BIBLIO>\n",
      "naca r847, 1946.\n",
      "</BIBLIO>\n",
      "<TEXT>\n",
      "  results are given of local skin-friction measurements in turbulent\n",
      "boundary layers over an equivalent air mach number range from 0.2 to 9.9\n",
      "and an over-all reynolds number variation of 2x10 to 100x10 .  direct\n",
      "force measurements were made by means of a floating element .  flows\n",
      "were two-dimensional over a smooth flat surface with essentially zero\n",
      "pressure gradient and with adiabatic conditions at the wall .  air and\n",
      "helium were used as working fluids .  an equivalence parameter for\n",
      "comparing boundary layers in different working fluids is derived and\n",
      "the experimental verification of the parameter is demonstrated .\n",
      "experimental results are compared with the results obtained by several\n",
      "methods of calculating skin friction in the turbulent boundary layer .\n",
      "</TEXT>\n",
      "</DOC>\n",
      "\n",
      "\n",
      "After  !-------------------!\n",
      "\n",
      "\n",
      "turbulent skin friction at high mach numbers and reynolds\n",
      "numbers in air and helium . nasa r82, 1960 .\n",
      " \n",
      "  results are given of local skin-friction measurements in turbulent\n",
      "boundary layers over an equivalent air mach number range from 0.2 to 9.9\n",
      "and an over-all reynolds number variation of 2x10 to 100x10 .  direct\n",
      "force measurements were made by means of a floating element .  flows\n",
      "were two-dimensional over a smooth flat surface with essentially zero\n",
      "pressure gradient and with adiabatic conditions at the wall .  air and\n",
      "helium were used as working fluids .  an equivalence parameter for\n",
      "comparing boundary layers in different working fluids is derived and\n",
      "the experimental verification of the parameter is demonstrated .\n",
      "experimental results are compared with the results obtained by several\n",
      "methods of calculating skin friction in the turbulent boundary layer .\n",
      "\n",
      "\n",
      "Before !-------------------!\n",
      "\n",
      "<DOC>\n",
      "<DOCNO>\n",
      "135\n",
      "</DOCNO>\n",
      "<TITLE>\n",
      "the calculation of wall shearing stress from heat-transfer measurements\n",
      "in compressible flows .\n",
      "</TITLE>\n",
      "<AUTHOR>\n",
      "nick s. diaconis\n",
      "</AUTHOR>\n",
      "<BIBLIO>\n",
      "lewis flight propulsion laboratory, naca, cleveland, ohio\n",
      "</BIBLIO>\n",
      "<TEXT>\n",
      "it has been shown by ludwieg that the wall shearing stress of a laminar\n",
      "or turbulent boundary layer in an incompressible flow can be determined\n",
      "from a heat-transfer measurement at the surface .  the instrument\n",
      "used in that investigation was essentially a small, locally insulated,\n",
      "heating element embedded in the test surface .  the size of the instrument\n",
      "was restricted by the condition that the thermal boundary layer\n",
      "generated by the heating element be contained locally within the laminar\n",
      "sublayer .  in the present analysis ludweig's theory for such an instrument\n",
      "is extended to compressible flow over an insulated flat plate .\n",
      "with the same limitations on the design and operation of the instrument\n",
      "as mentioned above, it can also be assumed for compressible laminar\n",
      "and turbulent boundary layers that only the flow in the immediate vicinity\n",
      "of the wall or the laminar sublayer will be affected in the region\n",
      "of the heated element .  this assumption then permits the use of the\n",
      "laminar boundary-layer equations as the governing equations for this\n",
      "analysis for both laminar and turbulent boundary layers .\n",
      "</TEXT>\n",
      "</DOC>\n",
      "\n",
      "\n",
      "After  !-------------------!\n",
      "\n",
      "\n",
      "the calculation of wall shearing stress from heat-transfer measurements\n",
      "in compressible flows .\n",
      " \n",
      "it has been shown by ludwieg that the wall shearing stress of a laminar\n",
      "or turbulent boundary layer in an incompressible flow can be determined\n",
      "from a heat-transfer measurement at the surface .  the instrument\n",
      "used in that investigation was essentially a small, locally insulated,\n",
      "heating element embedded in the test surface .  the size of the instrument\n",
      "was restricted by the condition that the thermal boundary layer\n",
      "generated by the heating element be contained locally within the laminar\n",
      "sublayer .  in the present analysis ludweig's theory for such an instrument\n",
      "is extended to compressible flow over an insulated flat plate .\n",
      "with the same limitations on the design and operation of the instrument\n",
      "as mentioned above, it can also be assumed for compressible laminar\n",
      "and turbulent boundary layers that only the flow in the immediate vicinity\n",
      "of the wall or the laminar sublayer will be affected in the region\n",
      "of the heated element .  this assumption then permits the use of the\n",
      "laminar boundary-layer equations as the governing equations for this\n",
      "analysis for both laminar and turbulent boundary layers .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the content for first 5 files before and after relevant extraction\n",
    "for i in range(5):\n",
    "    print(\"Before !-------------------!\")\n",
    "    print()\n",
    "    print(file_data[doc_id_to_name[i]])\n",
    "    print()\n",
    "    print(\"After  !-------------------!\")\n",
    "    print()\n",
    "    print(req_text[doc_id_to_name[i]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deee8fe1",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5688df5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text\n",
      "-----------------\n",
      "\n",
      "upper and lower bounds for the solution of the first\n",
      "biharmonic boundary value problem .\n",
      " \n",
      "  let w(x,y) be a solution of the boundary value problem\n",
      "where r is a plane\n",
      "domain with the boundary c .  the authors obtain upper and\n",
      "lower bounds for, the value of w at a point in r,\n",
      "by a method which is applicable to many other problems .\n",
      "  if u is a function satisfying the boundary conditions\n",
      "and v is a function satisfying the partial differential equation,\n",
      "then the authors obtain by applying green's classical\n",
      "identity and schwarz's inequality a pair of inequalities\n",
      "of the form where .\n",
      "  together with the function w the authors consider a\n",
      "function the solution of the boundary value problem\n",
      "on c, and in\n",
      "analogy with the functions u and v associated with the function\n",
      "w a pair of functions and associated with the function\n",
      ".  in the expression for derived from green's\n",
      "classical identity appears an unknown line integral containing\n",
      "the values of w and on c .  but the same line\n",
      "integral appears also in the expressions for\n",
      "to which the above inequalities are\n",
      "applicable .\n",
      "  in this way the authors obtain two inequalities of the form\n",
      "where b and b', respectively, are approximate\n",
      "values of .  in order to improve these bounds\n",
      "one may add to u a linear set of functions and to v a\n",
      "linear set of functions and then minimize h(u-v) in order\n",
      "to determine the coefficients of the best linear combinations .\n",
      "if the sequences and are complete in a certain sense\n",
      "defined by the authors the approximations will converge to\n",
      "the value .\n",
      "\n",
      "\n",
      "To lowercase\n",
      "-----------------\n",
      "\n",
      "upper and lower bounds for the solution of the first\n",
      "biharmonic boundary value problem .\n",
      " \n",
      "  let w(x,y) be a solution of the boundary value problem\n",
      "where r is a plane\n",
      "domain with the boundary c .  the authors obtain upper and\n",
      "lower bounds for, the value of w at a point in r,\n",
      "by a method which is applicable to many other problems .\n",
      "  if you is a function satisfying the boundary conditions\n",
      "and v is a function satisfying the partial differential equation,\n",
      "then the authors obtain by applying green's classical\n",
      "identity and schwarz's inequality a pair of inequalities\n",
      "of the form where .\n",
      "  together with the function w the authors consider a\n",
      "function the solution of the boundary value problem\n",
      "on c, and in\n",
      "analogy with the functions you and v associated with the function\n",
      "w a pair of functions and associated with the function\n",
      ".  in the expression for derived from green's\n",
      "classical identity appears an unknown line integral containing\n",
      "the values of w and on c .  but the same line\n",
      "integral appears also in the expressions for\n",
      "to which the above inequalities are\n",
      "applicable .\n",
      "  in this way the authors obtain two inequalities of the form\n",
      "where b and b', respectively, are approximate\n",
      "values of .  in order to improve these bounds\n",
      "one may add to you a linear set of functions and to v a\n",
      "linear set of functions and then minimize h(you-v) in order\n",
      "to determine the coefficients of the best linear combinations .\n",
      "if the sequences and are complete in a certain sense\n",
      "defined by the authors the approximations will converge to\n",
      "the value .\n",
      "\n",
      "\n",
      "Tokenized Text\n",
      "-----------------\n",
      "['upper', 'and', 'lower', 'bounds', 'for', 'the', 'solution', 'of', 'the', 'first', 'biharmonic', 'boundary', 'value', 'problem', '.', 'let', 'w', '(', 'x', ',', 'y', ')', 'be', 'a', 'solution', 'of', 'the', 'boundary', 'value', 'problem', 'where', 'r', 'is', 'a', 'plane', 'domain', 'with', 'the', 'boundary', 'c', '.', 'the', 'authors', 'obtain', 'upper', 'and', 'lower', 'bounds', 'for', ',', 'the', 'value', 'of', 'w', 'at', 'a', 'point', 'in', 'r', ',', 'by', 'a', 'method', 'which', 'is', 'applicable', 'to', 'many', 'other', 'problems', '.', 'if', 'you', 'is', 'a', 'function', 'satisfying', 'the', 'boundary', 'conditions', 'and', 'v', 'is', 'a', 'function', 'satisfying', 'the', 'partial', 'differential', 'equation', ',', 'then', 'the', 'authors', 'obtain', 'by', 'applying', 'green', \"'s\", 'classical', 'identity', 'and', 'schwarz', \"'s\", 'inequality', 'a', 'pair', 'of', 'inequalities', 'of', 'the', 'form', 'where', '.', 'together', 'with', 'the', 'function', 'w', 'the', 'authors', 'consider', 'a', 'function', 'the', 'solution', 'of', 'the', 'boundary', 'value', 'problem', 'on', 'c', ',', 'and', 'in', 'analogy', 'with', 'the', 'functions', 'you', 'and', 'v', 'associated', 'with', 'the', 'function', 'w', 'a', 'pair', 'of', 'functions', 'and', 'associated', 'with', 'the', 'function', '.', 'in', 'the', 'expression', 'for', 'derived', 'from', \"green's\", 'classical', 'identity', 'appears', 'an', 'unknown', 'line', 'integral', 'containing', 'the', 'values', 'of', 'w', 'and', 'on', 'c', '.', 'but', 'the', 'same', 'line', 'integral', 'appears', 'also', 'in', 'the', 'expressions', 'for', 'to', 'which', 'the', 'above', 'inequalities', 'are', 'applicable', '.', 'in', 'this', 'way', 'the', 'authors', 'obtain', 'two', 'inequalities', 'of', 'the', 'form', 'where', 'b', 'and', 'b', \"'\", ',', 'respectively', ',', 'are', 'approximate', 'values', 'of', '.', 'in', 'order', 'to', 'improve', 'these', 'bounds', 'one', 'may', 'add', 'to', 'you', 'a', 'linear', 'set', 'of', 'functions', 'and', 'to', 'v', 'a', 'linear', 'set', 'of', 'functions', 'and', 'then', 'minimize', 'h', '(', 'you-v', ')', 'in', 'order', 'to', 'determine', 'the', 'coefficients', 'of', 'the', 'best', 'linear', 'combinations', '.', 'if', 'the', 'sequences', 'and', 'are', 'complete', 'in', 'a', 'certain', 'sense', 'defined', 'by', 'the', 'authors', 'the', 'approximations', 'will', 'converge', 'to', 'the', 'value', '.']\n",
      "\n",
      "Removed Stopwords\n",
      "-----------------\n",
      "['upper', 'lower', 'bounds', 'solution', 'first', 'biharmonic', 'boundary', 'value', 'problem', '.', 'let', 'w', '(', 'x', ',', ')', 'solution', 'boundary', 'value', 'problem', 'r', 'plane', 'domain', 'boundary', 'c', '.', 'authors', 'obtain', 'upper', 'lower', 'bounds', ',', 'value', 'w', 'point', 'r', ',', 'method', 'applicable', 'many', 'problems', '.', 'function', 'satisfying', 'boundary', 'conditions', 'v', 'function', 'satisfying', 'partial', 'differential', 'equation', ',', 'authors', 'obtain', 'applying', 'green', \"'s\", 'classical', 'identity', 'schwarz', \"'s\", 'inequality', 'pair', 'inequalities', 'form', '.', 'together', 'function', 'w', 'authors', 'consider', 'function', 'solution', 'boundary', 'value', 'problem', 'c', ',', 'analogy', 'functions', 'v', 'associated', 'function', 'w', 'pair', 'functions', 'associated', 'function', '.', 'expression', 'derived', \"green's\", 'classical', 'identity', 'appears', 'unknown', 'line', 'integral', 'containing', 'values', 'w', 'c', '.', 'line', 'integral', 'appears', 'also', 'expressions', 'inequalities', 'applicable', '.', 'way', 'authors', 'obtain', 'two', 'inequalities', 'form', 'b', 'b', \"'\", ',', 'respectively', ',', 'approximate', 'values', '.', 'order', 'improve', 'bounds', 'one', 'may', 'add', 'linear', 'set', 'functions', 'v', 'linear', 'set', 'functions', 'minimize', 'h', '(', 'you-v', ')', 'order', 'determine', 'coefficients', 'best', 'linear', 'combinations', '.', 'sequences', 'complete', 'certain', 'sense', 'defined', 'authors', 'approximations', 'converge', 'value', '.']\n",
      "\n",
      "Removed Punctuations\n",
      "-----------------\n",
      "['upper', 'lower', 'bounds', 'solution', 'first', 'biharmonic', 'boundary', 'value', 'problem', '', 'let', 'w', '', 'x', '', '', 'solution', 'boundary', 'value', 'problem', 'r', 'plane', 'domain', 'boundary', 'c', '', 'authors', 'obtain', 'upper', 'lower', 'bounds', '', 'value', 'w', 'point', 'r', '', 'method', 'applicable', 'many', 'problems', '', 'function', 'satisfying', 'boundary', 'conditions', 'v', 'function', 'satisfying', 'partial', 'differential', 'equation', '', 'authors', 'obtain', 'applying', 'green', 's', 'classical', 'identity', 'schwarz', 's', 'inequality', 'pair', 'inequalities', 'form', '', 'together', 'function', 'w', 'authors', 'consider', 'function', 'solution', 'boundary', 'value', 'problem', 'c', '', 'analogy', 'functions', 'v', 'associated', 'function', 'w', 'pair', 'functions', 'associated', 'function', '', 'expression', 'derived', 'greens', 'classical', 'identity', 'appears', 'unknown', 'line', 'integral', 'containing', 'values', 'w', 'c', '', 'line', 'integral', 'appears', 'also', 'expressions', 'inequalities', 'applicable', '', 'way', 'authors', 'obtain', 'two', 'inequalities', 'form', 'b', 'b', '', '', 'respectively', '', 'approximate', 'values', '', 'order', 'improve', 'bounds', 'one', 'may', 'add', 'linear', 'set', 'functions', 'v', 'linear', 'set', 'functions', 'minimize', 'h', '', 'youv', '', 'order', 'determine', 'coefficients', 'best', 'linear', 'combinations', '', 'sequences', 'complete', 'certain', 'sense', 'defined', 'authors', 'approximations', 'converge', 'value', '']\n",
      "\n",
      "Removed Blankspaces\n",
      "-----------------\n",
      "['upper', 'lower', 'bounds', 'solution', 'first', 'biharmonic', 'boundary', 'value', 'problem', 'let', 'w', 'x', 'solution', 'boundary', 'value', 'problem', 'r', 'plane', 'domain', 'boundary', 'c', 'authors', 'obtain', 'upper', 'lower', 'bounds', 'value', 'w', 'point', 'r', 'method', 'applicable', 'many', 'problems', 'function', 'satisfying', 'boundary', 'conditions', 'v', 'function', 'satisfying', 'partial', 'differential', 'equation', 'authors', 'obtain', 'applying', 'green', 's', 'classical', 'identity', 'schwarz', 's', 'inequality', 'pair', 'inequalities', 'form', 'together', 'function', 'w', 'authors', 'consider', 'function', 'solution', 'boundary', 'value', 'problem', 'c', 'analogy', 'functions', 'v', 'associated', 'function', 'w', 'pair', 'functions', 'associated', 'function', 'expression', 'derived', 'greens', 'classical', 'identity', 'appears', 'unknown', 'line', 'integral', 'containing', 'values', 'w', 'c', 'line', 'integral', 'appears', 'also', 'expressions', 'inequalities', 'applicable', 'way', 'authors', 'obtain', 'two', 'inequalities', 'form', 'b', 'b', 'respectively', 'approximate', 'values', 'order', 'improve', 'bounds', 'one', 'may', 'add', 'linear', 'set', 'functions', 'v', 'linear', 'set', 'functions', 'minimize', 'h', 'youv', 'order', 'determine', 'coefficients', 'best', 'linear', 'combinations', 'sequences', 'complete', 'certain', 'sense', 'defined', 'authors', 'approximations', 'converge', 'value']\n",
      "\n",
      "Original Text\n",
      "-----------------\n",
      "\n",
      "the calculation of aerodynamic loading on surfaces of any shape .\n",
      " \n",
      "the object of the report is to establish a routine method for the calculation\n",
      "of aerodynamic loads on wings of arbitrary shape . the method\n",
      "developed is based on potential theory and uses a general mathematical\n",
      "formula for continuous loading on a wing which is equivalent to a double\n",
      " fourier series with unknown coefficients . in order to evaluate the\n",
      "unknown coefficients the continuous loading is split up into a regular\n",
      "pattern of horseshoe vortices, the strengths of which are proportional\n",
      "to the unknown coefficients and to standard factors which are given in a\n",
      " table . the total downwash at chosen pivotal points is obtained by\n",
      "summing the downwashes due to the individual vortices, a process which\n",
      "is simplified by the use of specially prepared tables of the properties\n",
      "of the horseshoe vortex . by equating the downwash to the slope of the\n",
      "wing at each pivotal point, simultaneous equations are obtained, the\n",
      "solution of which defines the unknown coefficients .\n",
      "the first layout involves a total of 76 vortices over the wing, and a\n",
      "second layout, involving a total of 84, is shown to be of superior\n",
      "accuracy . the effect on the solution of the number of pivotal points is\n",
      " investigated and it is concluded that by a suitable choice, it is unnecessary\n",
      "to use a large number . results for a rectangular wing at\n",
      "with those obtained by other workers and it appears that there may be\n",
      "errors in published results in at least one of these cases . immediate\n",
      "development includes the application to the calculation of the characteristics\n",
      "of actual sweptback wings, including rotary derivatives, and\n",
      " future development includes also applications in wind tunnel design and\n",
      " technique .\n",
      "\n",
      "\n",
      "To lowercase\n",
      "-----------------\n",
      "\n",
      "the calculation of aerodynamic loading on surfaces of any shape .\n",
      " \n",
      "the object of the report is to establish a routine method for the calculation\n",
      "of aerodynamic loads on wings of arbitrary shape . the method\n",
      "developed is based on potential theory and uses a general mathematical\n",
      "formula for continuous loading on a wing which is equivalent to a double\n",
      " fourier series with unknown coefficients . in order to evaluate the\n",
      "unknown coefficients the continuous loading is split up into a regular\n",
      "pattern of horseshoe vortices, the strengths of which are proportional\n",
      "to the unknown coefficients and to standard factors which are given in a\n",
      " table . the total downwash at chosen pivotal points is obtained by\n",
      "summing the downwashes due to the individual vortices, a process which\n",
      "is simplified by the use of specially prepared tables of the properties\n",
      "of the horseshoe vortex . by equating the downwash to the slope of the\n",
      "wing at each pivotal point, simultaneous equations are obtained, the\n",
      "solution of which defines the unknown coefficients .\n",
      "the first layout involves a total of 76 vortices over the wing, and a\n",
      "second layout, involving a total of 84, is shown to be of superior\n",
      "accuracy . the effect on the solution of the number of pivotal points is\n",
      " investigated and it is concluded that by a suitable choice, it is unnecessary\n",
      "to use a large number . results for a rectangular wing at\n",
      "with those obtained by other workers and it appears that there may be\n",
      "errors in published results in at least one of these cases . immediate\n",
      "development includes the application to the calculation of the characteristics\n",
      "of actual sweptback wings, including rotary derivatives, and\n",
      " future development includes also applications in wind tunnel design and\n",
      " technique .\n",
      "\n",
      "\n",
      "Tokenized Text\n",
      "-----------------\n",
      "['the', 'calculation', 'of', 'aerodynamic', 'loading', 'on', 'surfaces', 'of', 'any', 'shape', '.', 'the', 'object', 'of', 'the', 'report', 'is', 'to', 'establish', 'a', 'routine', 'method', 'for', 'the', 'calculation', 'of', 'aerodynamic', 'loads', 'on', 'wings', 'of', 'arbitrary', 'shape', '.', 'the', 'method', 'developed', 'is', 'based', 'on', 'potential', 'theory', 'and', 'uses', 'a', 'general', 'mathematical', 'formula', 'for', 'continuous', 'loading', 'on', 'a', 'wing', 'which', 'is', 'equivalent', 'to', 'a', 'double', 'fourier', 'series', 'with', 'unknown', 'coefficients', '.', 'in', 'order', 'to', 'evaluate', 'the', 'unknown', 'coefficients', 'the', 'continuous', 'loading', 'is', 'split', 'up', 'into', 'a', 'regular', 'pattern', 'of', 'horseshoe', 'vortices', ',', 'the', 'strengths', 'of', 'which', 'are', 'proportional', 'to', 'the', 'unknown', 'coefficients', 'and', 'to', 'standard', 'factors', 'which', 'are', 'given', 'in', 'a', 'table', '.', 'the', 'total', 'downwash', 'at', 'chosen', 'pivotal', 'points', 'is', 'obtained', 'by', 'summing', 'the', 'downwashes', 'due', 'to', 'the', 'individual', 'vortices', ',', 'a', 'process', 'which', 'is', 'simplified', 'by', 'the', 'use', 'of', 'specially', 'prepared', 'tables', 'of', 'the', 'properties', 'of', 'the', 'horseshoe', 'vortex', '.', 'by', 'equating', 'the', 'downwash', 'to', 'the', 'slope', 'of', 'the', 'wing', 'at', 'each', 'pivotal', 'point', ',', 'simultaneous', 'equations', 'are', 'obtained', ',', 'the', 'solution', 'of', 'which', 'defines', 'the', 'unknown', 'coefficients', '.', 'the', 'first', 'layout', 'involves', 'a', 'total', 'of', '76', 'vortices', 'over', 'the', 'wing', ',', 'and', 'a', 'second', 'layout', ',', 'involving', 'a', 'total', 'of', '84', ',', 'is', 'shown', 'to', 'be', 'of', 'superior', 'accuracy', '.', 'the', 'effect', 'on', 'the', 'solution', 'of', 'the', 'number', 'of', 'pivotal', 'points', 'is', 'investigated', 'and', 'it', 'is', 'concluded', 'that', 'by', 'a', 'suitable', 'choice', ',', 'it', 'is', 'unnecessary', 'to', 'use', 'a', 'large', 'number', '.', 'results', 'for', 'a', 'rectangular', 'wing', 'at', 'with', 'those', 'obtained', 'by', 'other', 'workers', 'and', 'it', 'appears', 'that', 'there', 'may', 'be', 'errors', 'in', 'published', 'results', 'in', 'at', 'least', 'one', 'of', 'these', 'cases', '.', 'immediate', 'development', 'includes', 'the', 'application', 'to', 'the', 'calculation', 'of', 'the', 'characteristics', 'of', 'actual', 'sweptback', 'wings', ',', 'including', 'rotary', 'derivatives', ',', 'and', 'future', 'development', 'includes', 'also', 'applications', 'in', 'wind', 'tunnel', 'design', 'and', 'technique', '.']\n",
      "\n",
      "Removed Stopwords\n",
      "-----------------\n",
      "['calculation', 'aerodynamic', 'loading', 'surfaces', 'shape', '.', 'object', 'report', 'establish', 'routine', 'method', 'calculation', 'aerodynamic', 'loads', 'wings', 'arbitrary', 'shape', '.', 'method', 'developed', 'based', 'potential', 'theory', 'uses', 'general', 'mathematical', 'formula', 'continuous', 'loading', 'wing', 'equivalent', 'double', 'fourier', 'series', 'unknown', 'coefficients', '.', 'order', 'evaluate', 'unknown', 'coefficients', 'continuous', 'loading', 'split', 'regular', 'pattern', 'horseshoe', 'vortices', ',', 'strengths', 'proportional', 'unknown', 'coefficients', 'standard', 'factors', 'given', 'table', '.', 'total', 'downwash', 'chosen', 'pivotal', 'points', 'obtained', 'summing', 'downwashes', 'due', 'individual', 'vortices', ',', 'process', 'simplified', 'use', 'specially', 'prepared', 'tables', 'properties', 'horseshoe', 'vortex', '.', 'equating', 'downwash', 'slope', 'wing', 'pivotal', 'point', ',', 'simultaneous', 'equations', 'obtained', ',', 'solution', 'defines', 'unknown', 'coefficients', '.', 'first', 'layout', 'involves', 'total', '76', 'vortices', 'wing', ',', 'second', 'layout', ',', 'involving', 'total', '84', ',', 'shown', 'superior', 'accuracy', '.', 'effect', 'solution', 'number', 'pivotal', 'points', 'investigated', 'concluded', 'suitable', 'choice', ',', 'unnecessary', 'use', 'large', 'number', '.', 'results', 'rectangular', 'wing', 'obtained', 'workers', 'appears', 'may', 'errors', 'published', 'results', 'least', 'one', 'cases', '.', 'immediate', 'development', 'includes', 'application', 'calculation', 'characteristics', 'actual', 'sweptback', 'wings', ',', 'including', 'rotary', 'derivatives', ',', 'future', 'development', 'includes', 'also', 'applications', 'wind', 'tunnel', 'design', 'technique', '.']\n",
      "\n",
      "Removed Punctuations\n",
      "-----------------\n",
      "['calculation', 'aerodynamic', 'loading', 'surfaces', 'shape', '', 'object', 'report', 'establish', 'routine', 'method', 'calculation', 'aerodynamic', 'loads', 'wings', 'arbitrary', 'shape', '', 'method', 'developed', 'based', 'potential', 'theory', 'uses', 'general', 'mathematical', 'formula', 'continuous', 'loading', 'wing', 'equivalent', 'double', 'fourier', 'series', 'unknown', 'coefficients', '', 'order', 'evaluate', 'unknown', 'coefficients', 'continuous', 'loading', 'split', 'regular', 'pattern', 'horseshoe', 'vortices', '', 'strengths', 'proportional', 'unknown', 'coefficients', 'standard', 'factors', 'given', 'table', '', 'total', 'downwash', 'chosen', 'pivotal', 'points', 'obtained', 'summing', 'downwashes', 'due', 'individual', 'vortices', '', 'process', 'simplified', 'use', 'specially', 'prepared', 'tables', 'properties', 'horseshoe', 'vortex', '', 'equating', 'downwash', 'slope', 'wing', 'pivotal', 'point', '', 'simultaneous', 'equations', 'obtained', '', 'solution', 'defines', 'unknown', 'coefficients', '', 'first', 'layout', 'involves', 'total', '76', 'vortices', 'wing', '', 'second', 'layout', '', 'involving', 'total', '84', '', 'shown', 'superior', 'accuracy', '', 'effect', 'solution', 'number', 'pivotal', 'points', 'investigated', 'concluded', 'suitable', 'choice', '', 'unnecessary', 'use', 'large', 'number', '', 'results', 'rectangular', 'wing', 'obtained', 'workers', 'appears', 'may', 'errors', 'published', 'results', 'least', 'one', 'cases', '', 'immediate', 'development', 'includes', 'application', 'calculation', 'characteristics', 'actual', 'sweptback', 'wings', '', 'including', 'rotary', 'derivatives', '', 'future', 'development', 'includes', 'also', 'applications', 'wind', 'tunnel', 'design', 'technique', '']\n",
      "\n",
      "Removed Blankspaces\n",
      "-----------------\n",
      "['calculation', 'aerodynamic', 'loading', 'surfaces', 'shape', 'object', 'report', 'establish', 'routine', 'method', 'calculation', 'aerodynamic', 'loads', 'wings', 'arbitrary', 'shape', 'method', 'developed', 'based', 'potential', 'theory', 'uses', 'general', 'mathematical', 'formula', 'continuous', 'loading', 'wing', 'equivalent', 'double', 'fourier', 'series', 'unknown', 'coefficients', 'order', 'evaluate', 'unknown', 'coefficients', 'continuous', 'loading', 'split', 'regular', 'pattern', 'horseshoe', 'vortices', 'strengths', 'proportional', 'unknown', 'coefficients', 'standard', 'factors', 'given', 'table', 'total', 'downwash', 'chosen', 'pivotal', 'points', 'obtained', 'summing', 'downwashes', 'due', 'individual', 'vortices', 'process', 'simplified', 'use', 'specially', 'prepared', 'tables', 'properties', 'horseshoe', 'vortex', 'equating', 'downwash', 'slope', 'wing', 'pivotal', 'point', 'simultaneous', 'equations', 'obtained', 'solution', 'defines', 'unknown', 'coefficients', 'first', 'layout', 'involves', 'total', '76', 'vortices', 'wing', 'second', 'layout', 'involving', 'total', '84', 'shown', 'superior', 'accuracy', 'effect', 'solution', 'number', 'pivotal', 'points', 'investigated', 'concluded', 'suitable', 'choice', 'unnecessary', 'use', 'large', 'number', 'results', 'rectangular', 'wing', 'obtained', 'workers', 'appears', 'may', 'errors', 'published', 'results', 'least', 'one', 'cases', 'immediate', 'development', 'includes', 'application', 'calculation', 'characteristics', 'actual', 'sweptback', 'wings', 'including', 'rotary', 'derivatives', 'future', 'development', 'includes', 'also', 'applications', 'wind', 'tunnel', 'design', 'technique']\n",
      "\n",
      "Original Text\n",
      "-----------------\n",
      "\n",
      "air flow in a separating laminar boundary layer .\n",
      " \n",
      "  the speed distribution in a laminar boundary layer on\n",
      "the surface of an elliptic cylinder, of major and minor\n",
      "axes 11.78 and 3.98 inches, respectively, has been determined\n",
      "by means of a hot-wire anemometer .  the direction\n",
      "of the impinging air stream was parallel to the major axis .\n",
      "special attention was given to the speed distribution in\n",
      "the region of separation and to the exact location of the\n",
      "point of separation .  an approximate method, developed\n",
      "by k. pohlhausen for computing the speed distribution,\n",
      "the thickness of the layer, and the point of separation, is\n",
      "described in detail,. and speed-distribution curves calculated\n",
      "by this method are presented for comparison with\n",
      "experiment .  good agreement is obtained along the forward\n",
      "part of the cylinder, but pohlhausen's method fails\n",
      "shortly before the separation point is reached and consequently\n",
      "cannot be used to locate this point .\n",
      "  the work was carried out at the national bureau of\n",
      "standards with the cooperation and financial assistance\n",
      "of the national advisory committee for aeronautics .\n",
      "\n",
      "\n",
      "To lowercase\n",
      "-----------------\n",
      "\n",
      "air flow in a separating laminar boundary layer .\n",
      " \n",
      "  the speed distribution in a laminar boundary layer on\n",
      "the surface of an elliptic cylinder, of major and minor\n",
      "axes 11.78 and 3.98 inches, respectively, has been determined\n",
      "by means of a hot-wire anemometer .  the direction\n",
      "of the impinging air stream was parallel to the major axis .\n",
      "special attention was given to the speed distribution in\n",
      "the region of separation and to the exact location of the\n",
      "point of separation .  an approximate method, developed\n",
      "by k. pohlhausen for computing the speed distribution,\n",
      "the thickness of the layer, and the point of separation, is\n",
      "described in detail,. and speed-distribution curves calculated\n",
      "by this method are presented for comparison with\n",
      "experiment .  good agreement is obtained along the forward\n",
      "part of the cylinder, but pohlhausen's method fails\n",
      "shortly before the separation point is reached and consequently\n",
      "cannot be used to locate this point .\n",
      "  the work was carried out at the national bureau of\n",
      "standards with the cooperation and financial assistance\n",
      "of the national advisory committee for aeronautics .\n",
      "\n",
      "\n",
      "Tokenized Text\n",
      "-----------------\n",
      "['air', 'flow', 'in', 'a', 'separating', 'laminar', 'boundary', 'layer', '.', 'the', 'speed', 'distribution', 'in', 'a', 'laminar', 'boundary', 'layer', 'on', 'the', 'surface', 'of', 'an', 'elliptic', 'cylinder', ',', 'of', 'major', 'and', 'minor', 'axes', '11.78', 'and', '3.98', 'inches', ',', 'respectively', ',', 'has', 'been', 'determined', 'by', 'means', 'of', 'a', 'hot-wire', 'anemometer', '.', 'the', 'direction', 'of', 'the', 'impinging', 'air', 'stream', 'was', 'parallel', 'to', 'the', 'major', 'axis', '.', 'special', 'attention', 'was', 'given', 'to', 'the', 'speed', 'distribution', 'in', 'the', 'region', 'of', 'separation', 'and', 'to', 'the', 'exact', 'location', 'of', 'the', 'point', 'of', 'separation', '.', 'an', 'approximate', 'method', ',', 'developed', 'by', 'k.', 'pohlhausen', 'for', 'computing', 'the', 'speed', 'distribution', ',', 'the', 'thickness', 'of', 'the', 'layer', ',', 'and', 'the', 'point', 'of', 'separation', ',', 'is', 'described', 'in', 'detail', ',', '.', 'and', 'speed-distribution', 'curves', 'calculated', 'by', 'this', 'method', 'are', 'presented', 'for', 'comparison', 'with', 'experiment', '.', 'good', 'agreement', 'is', 'obtained', 'along', 'the', 'forward', 'part', 'of', 'the', 'cylinder', ',', 'but', 'pohlhausen', \"'s\", 'method', 'fails', 'shortly', 'before', 'the', 'separation', 'point', 'is', 'reached', 'and', 'consequently', 'can', 'not', 'be', 'used', 'to', 'locate', 'this', 'point', '.', 'the', 'work', 'was', 'carried', 'out', 'at', 'the', 'national', 'bureau', 'of', 'standards', 'with', 'the', 'cooperation', 'and', 'financial', 'assistance', 'of', 'the', 'national', 'advisory', 'committee', 'for', 'aeronautics', '.']\n",
      "\n",
      "Removed Stopwords\n",
      "-----------------\n",
      "['air', 'flow', 'separating', 'laminar', 'boundary', 'layer', '.', 'speed', 'distribution', 'laminar', 'boundary', 'layer', 'surface', 'elliptic', 'cylinder', ',', 'major', 'minor', 'axes', '11.78', '3.98', 'inches', ',', 'respectively', ',', 'determined', 'means', 'hot-wire', 'anemometer', '.', 'direction', 'impinging', 'air', 'stream', 'parallel', 'major', 'axis', '.', 'special', 'attention', 'given', 'speed', 'distribution', 'region', 'separation', 'exact', 'location', 'point', 'separation', '.', 'approximate', 'method', ',', 'developed', 'k.', 'pohlhausen', 'computing', 'speed', 'distribution', ',', 'thickness', 'layer', ',', 'point', 'separation', ',', 'described', 'detail', ',', '.', 'speed-distribution', 'curves', 'calculated', 'method', 'presented', 'comparison', 'experiment', '.', 'good', 'agreement', 'obtained', 'along', 'forward', 'part', 'cylinder', ',', 'pohlhausen', \"'s\", 'method', 'fails', 'shortly', 'separation', 'point', 'reached', 'consequently', 'used', 'locate', 'point', '.', 'work', 'carried', 'national', 'bureau', 'standards', 'cooperation', 'financial', 'assistance', 'national', 'advisory', 'committee', 'aeronautics', '.']\n",
      "\n",
      "Removed Punctuations\n",
      "-----------------\n",
      "['air', 'flow', 'separating', 'laminar', 'boundary', 'layer', '', 'speed', 'distribution', 'laminar', 'boundary', 'layer', 'surface', 'elliptic', 'cylinder', '', 'major', 'minor', 'axes', '1178', '398', 'inches', '', 'respectively', '', 'determined', 'means', 'hotwire', 'anemometer', '', 'direction', 'impinging', 'air', 'stream', 'parallel', 'major', 'axis', '', 'special', 'attention', 'given', 'speed', 'distribution', 'region', 'separation', 'exact', 'location', 'point', 'separation', '', 'approximate', 'method', '', 'developed', 'k', 'pohlhausen', 'computing', 'speed', 'distribution', '', 'thickness', 'layer', '', 'point', 'separation', '', 'described', 'detail', '', '', 'speeddistribution', 'curves', 'calculated', 'method', 'presented', 'comparison', 'experiment', '', 'good', 'agreement', 'obtained', 'along', 'forward', 'part', 'cylinder', '', 'pohlhausen', 's', 'method', 'fails', 'shortly', 'separation', 'point', 'reached', 'consequently', 'used', 'locate', 'point', '', 'work', 'carried', 'national', 'bureau', 'standards', 'cooperation', 'financial', 'assistance', 'national', 'advisory', 'committee', 'aeronautics', '']\n",
      "\n",
      "Removed Blankspaces\n",
      "-----------------\n",
      "['air', 'flow', 'separating', 'laminar', 'boundary', 'layer', 'speed', 'distribution', 'laminar', 'boundary', 'layer', 'surface', 'elliptic', 'cylinder', 'major', 'minor', 'axes', '1178', '398', 'inches', 'respectively', 'determined', 'means', 'hotwire', 'anemometer', 'direction', 'impinging', 'air', 'stream', 'parallel', 'major', 'axis', 'special', 'attention', 'given', 'speed', 'distribution', 'region', 'separation', 'exact', 'location', 'point', 'separation', 'approximate', 'method', 'developed', 'k', 'pohlhausen', 'computing', 'speed', 'distribution', 'thickness', 'layer', 'point', 'separation', 'described', 'detail', 'speeddistribution', 'curves', 'calculated', 'method', 'presented', 'comparison', 'experiment', 'good', 'agreement', 'obtained', 'along', 'forward', 'part', 'cylinder', 'pohlhausen', 's', 'method', 'fails', 'shortly', 'separation', 'point', 'reached', 'consequently', 'used', 'locate', 'point', 'work', 'carried', 'national', 'bureau', 'standards', 'cooperation', 'financial', 'assistance', 'national', 'advisory', 'committee', 'aeronautics']\n",
      "\n",
      "Original Text\n",
      "-----------------\n",
      "\n",
      "turbulent skin friction at high mach numbers and reynolds\n",
      "numbers in air and helium . nasa r82, 1960 .\n",
      " \n",
      "  results are given of local skin-friction measurements in turbulent\n",
      "boundary layers over an equivalent air mach number range from 0.2 to 9.9\n",
      "and an over-all reynolds number variation of 2x10 to 100x10 .  direct\n",
      "force measurements were made by means of a floating element .  flows\n",
      "were two-dimensional over a smooth flat surface with essentially zero\n",
      "pressure gradient and with adiabatic conditions at the wall .  air and\n",
      "helium were used as working fluids .  an equivalence parameter for\n",
      "comparing boundary layers in different working fluids is derived and\n",
      "the experimental verification of the parameter is demonstrated .\n",
      "experimental results are compared with the results obtained by several\n",
      "methods of calculating skin friction in the turbulent boundary layer .\n",
      "\n",
      "\n",
      "To lowercase\n",
      "-----------------\n",
      "\n",
      "turbulent skin friction at high mach numbers and reynolds\n",
      "numbers in air and helium . nasa r82, 1960 .\n",
      " \n",
      "  results are given of local skin-friction measurements in turbulent\n",
      "boundary layers over an equivalent air mach number range from 0.2 to 9.9\n",
      "and an over-all reynolds number variation of 2x10 to 100x10 .  direct\n",
      "force measurements were made by means of a floating element .  flows\n",
      "were two-dimensional over a smooth flat surface with essentially zero\n",
      "pressure gradient and with adiabatic conditions at the wall .  air and\n",
      "helium were used as working fluids .  an equivalence parameter for\n",
      "comparing boundary layers in different working fluids is derived and\n",
      "the experimental verification of the parameter is demonstrated .\n",
      "experimental results are compared with the results obtained by several\n",
      "methods of calculating skin friction in the turbulent boundary layer .\n",
      "\n",
      "\n",
      "Tokenized Text\n",
      "-----------------\n",
      "['turbulent', 'skin', 'friction', 'at', 'high', 'mach', 'numbers', 'and', 'reynolds', 'numbers', 'in', 'air', 'and', 'helium', '.', 'nasa', 'r82', ',', '1960', '.', 'results', 'are', 'given', 'of', 'local', 'skin-friction', 'measurements', 'in', 'turbulent', 'boundary', 'layers', 'over', 'an', 'equivalent', 'air', 'mach', 'number', 'range', 'from', '0.2', 'to', '9.9', 'and', 'an', 'over-all', 'reynolds', 'number', 'variation', 'of', '2x10', 'to', '100x10', '.', 'direct', 'force', 'measurements', 'were', 'made', 'by', 'means', 'of', 'a', 'floating', 'element', '.', 'flows', 'were', 'two-dimensional', 'over', 'a', 'smooth', 'flat', 'surface', 'with', 'essentially', 'zero', 'pressure', 'gradient', 'and', 'with', 'adiabatic', 'conditions', 'at', 'the', 'wall', '.', 'air', 'and', 'helium', 'were', 'used', 'as', 'working', 'fluids', '.', 'an', 'equivalence', 'parameter', 'for', 'comparing', 'boundary', 'layers', 'in', 'different', 'working', 'fluids', 'is', 'derived', 'and', 'the', 'experimental', 'verification', 'of', 'the', 'parameter', 'is', 'demonstrated', '.', 'experimental', 'results', 'are', 'compared', 'with', 'the', 'results', 'obtained', 'by', 'several', 'methods', 'of', 'calculating', 'skin', 'friction', 'in', 'the', 'turbulent', 'boundary', 'layer', '.']\n",
      "\n",
      "Removed Stopwords\n",
      "-----------------\n",
      "['turbulent', 'skin', 'friction', 'high', 'mach', 'numbers', 'reynolds', 'numbers', 'air', 'helium', '.', 'nasa', 'r82', ',', '1960', '.', 'results', 'given', 'local', 'skin-friction', 'measurements', 'turbulent', 'boundary', 'layers', 'equivalent', 'air', 'mach', 'number', 'range', '0.2', '9.9', 'over-all', 'reynolds', 'number', 'variation', '2x10', '100x10', '.', 'direct', 'force', 'measurements', 'made', 'means', 'floating', 'element', '.', 'flows', 'two-dimensional', 'smooth', 'flat', 'surface', 'essentially', 'zero', 'pressure', 'gradient', 'adiabatic', 'conditions', 'wall', '.', 'air', 'helium', 'used', 'working', 'fluids', '.', 'equivalence', 'parameter', 'comparing', 'boundary', 'layers', 'different', 'working', 'fluids', 'derived', 'experimental', 'verification', 'parameter', 'demonstrated', '.', 'experimental', 'results', 'compared', 'results', 'obtained', 'several', 'methods', 'calculating', 'skin', 'friction', 'turbulent', 'boundary', 'layer', '.']\n",
      "\n",
      "Removed Punctuations\n",
      "-----------------\n",
      "['turbulent', 'skin', 'friction', 'high', 'mach', 'numbers', 'reynolds', 'numbers', 'air', 'helium', '', 'nasa', 'r82', '', '1960', '', 'results', 'given', 'local', 'skinfriction', 'measurements', 'turbulent', 'boundary', 'layers', 'equivalent', 'air', 'mach', 'number', 'range', '02', '99', 'overall', 'reynolds', 'number', 'variation', '2x10', '100x10', '', 'direct', 'force', 'measurements', 'made', 'means', 'floating', 'element', '', 'flows', 'twodimensional', 'smooth', 'flat', 'surface', 'essentially', 'zero', 'pressure', 'gradient', 'adiabatic', 'conditions', 'wall', '', 'air', 'helium', 'used', 'working', 'fluids', '', 'equivalence', 'parameter', 'comparing', 'boundary', 'layers', 'different', 'working', 'fluids', 'derived', 'experimental', 'verification', 'parameter', 'demonstrated', '', 'experimental', 'results', 'compared', 'results', 'obtained', 'several', 'methods', 'calculating', 'skin', 'friction', 'turbulent', 'boundary', 'layer', '']\n",
      "\n",
      "Removed Blankspaces\n",
      "-----------------\n",
      "['turbulent', 'skin', 'friction', 'high', 'mach', 'numbers', 'reynolds', 'numbers', 'air', 'helium', 'nasa', 'r82', '1960', 'results', 'given', 'local', 'skinfriction', 'measurements', 'turbulent', 'boundary', 'layers', 'equivalent', 'air', 'mach', 'number', 'range', '02', '99', 'overall', 'reynolds', 'number', 'variation', '2x10', '100x10', 'direct', 'force', 'measurements', 'made', 'means', 'floating', 'element', 'flows', 'twodimensional', 'smooth', 'flat', 'surface', 'essentially', 'zero', 'pressure', 'gradient', 'adiabatic', 'conditions', 'wall', 'air', 'helium', 'used', 'working', 'fluids', 'equivalence', 'parameter', 'comparing', 'boundary', 'layers', 'different', 'working', 'fluids', 'derived', 'experimental', 'verification', 'parameter', 'demonstrated', 'experimental', 'results', 'compared', 'results', 'obtained', 'several', 'methods', 'calculating', 'skin', 'friction', 'turbulent', 'boundary', 'layer']\n",
      "\n",
      "Original Text\n",
      "-----------------\n",
      "\n",
      "the calculation of wall shearing stress from heat-transfer measurements\n",
      "in compressible flows .\n",
      " \n",
      "it has been shown by ludwieg that the wall shearing stress of a laminar\n",
      "or turbulent boundary layer in an incompressible flow can be determined\n",
      "from a heat-transfer measurement at the surface .  the instrument\n",
      "used in that investigation was essentially a small, locally insulated,\n",
      "heating element embedded in the test surface .  the size of the instrument\n",
      "was restricted by the condition that the thermal boundary layer\n",
      "generated by the heating element be contained locally within the laminar\n",
      "sublayer .  in the present analysis ludweig's theory for such an instrument\n",
      "is extended to compressible flow over an insulated flat plate .\n",
      "with the same limitations on the design and operation of the instrument\n",
      "as mentioned above, it can also be assumed for compressible laminar\n",
      "and turbulent boundary layers that only the flow in the immediate vicinity\n",
      "of the wall or the laminar sublayer will be affected in the region\n",
      "of the heated element .  this assumption then permits the use of the\n",
      "laminar boundary-layer equations as the governing equations for this\n",
      "analysis for both laminar and turbulent boundary layers .\n",
      "\n",
      "\n",
      "To lowercase\n",
      "-----------------\n",
      "\n",
      "the calculation of wall shearing stress from heat-transfer measurements\n",
      "in compressible flows .\n",
      " \n",
      "it has been shown by ludwieg that the wall shearing stress of a laminar\n",
      "or turbulent boundary layer in an incompressible flow can be determined\n",
      "from a heat-transfer measurement at the surface .  the instrument\n",
      "used in that investigation was essentially a small, locally insulated,\n",
      "heating element embedded in the test surface .  the size of the instrument\n",
      "was restricted by the condition that the thermal boundary layer\n",
      "generated by the heating element be contained locally within the laminar\n",
      "sublayer .  in the present analysis ludweig's theory for such an instrument\n",
      "is extended to compressible flow over an insulated flat plate .\n",
      "with the same limitations on the design and operation of the instrument\n",
      "as mentioned above, it can also be assumed for compressible laminar\n",
      "and turbulent boundary layers that only the flow in the immediate vicinity\n",
      "of the wall or the laminar sublayer will be affected in the region\n",
      "of the heated element .  this assumption then permits the use of the\n",
      "laminar boundary-layer equations as the governing equations for this\n",
      "analysis for both laminar and turbulent boundary layers .\n",
      "\n",
      "\n",
      "Tokenized Text\n",
      "-----------------\n",
      "['the', 'calculation', 'of', 'wall', 'shearing', 'stress', 'from', 'heat-transfer', 'measurements', 'in', 'compressible', 'flows', '.', 'it', 'has', 'been', 'shown', 'by', 'ludwieg', 'that', 'the', 'wall', 'shearing', 'stress', 'of', 'a', 'laminar', 'or', 'turbulent', 'boundary', 'layer', 'in', 'an', 'incompressible', 'flow', 'can', 'be', 'determined', 'from', 'a', 'heat-transfer', 'measurement', 'at', 'the', 'surface', '.', 'the', 'instrument', 'used', 'in', 'that', 'investigation', 'was', 'essentially', 'a', 'small', ',', 'locally', 'insulated', ',', 'heating', 'element', 'embedded', 'in', 'the', 'test', 'surface', '.', 'the', 'size', 'of', 'the', 'instrument', 'was', 'restricted', 'by', 'the', 'condition', 'that', 'the', 'thermal', 'boundary', 'layer', 'generated', 'by', 'the', 'heating', 'element', 'be', 'contained', 'locally', 'within', 'the', 'laminar', 'sublayer', '.', 'in', 'the', 'present', 'analysis', 'ludweig', \"'s\", 'theory', 'for', 'such', 'an', 'instrument', 'is', 'extended', 'to', 'compressible', 'flow', 'over', 'an', 'insulated', 'flat', 'plate', '.', 'with', 'the', 'same', 'limitations', 'on', 'the', 'design', 'and', 'operation', 'of', 'the', 'instrument', 'as', 'mentioned', 'above', ',', 'it', 'can', 'also', 'be', 'assumed', 'for', 'compressible', 'laminar', 'and', 'turbulent', 'boundary', 'layers', 'that', 'only', 'the', 'flow', 'in', 'the', 'immediate', 'vicinity', 'of', 'the', 'wall', 'or', 'the', 'laminar', 'sublayer', 'will', 'be', 'affected', 'in', 'the', 'region', 'of', 'the', 'heated', 'element', '.', 'this', 'assumption', 'then', 'permits', 'the', 'use', 'of', 'the', 'laminar', 'boundary-layer', 'equations', 'as', 'the', 'governing', 'equations', 'for', 'this', 'analysis', 'for', 'both', 'laminar', 'and', 'turbulent', 'boundary', 'layers', '.']\n",
      "\n",
      "Removed Stopwords\n",
      "-----------------\n",
      "['calculation', 'wall', 'shearing', 'stress', 'heat-transfer', 'measurements', 'compressible', 'flows', '.', 'shown', 'ludwieg', 'wall', 'shearing', 'stress', 'laminar', 'turbulent', 'boundary', 'layer', 'incompressible', 'flow', 'determined', 'heat-transfer', 'measurement', 'surface', '.', 'instrument', 'used', 'investigation', 'essentially', 'small', ',', 'locally', 'insulated', ',', 'heating', 'element', 'embedded', 'test', 'surface', '.', 'size', 'instrument', 'restricted', 'condition', 'thermal', 'boundary', 'layer', 'generated', 'heating', 'element', 'contained', 'locally', 'within', 'laminar', 'sublayer', '.', 'present', 'analysis', 'ludweig', \"'s\", 'theory', 'instrument', 'extended', 'compressible', 'flow', 'insulated', 'flat', 'plate', '.', 'limitations', 'design', 'operation', 'instrument', 'mentioned', ',', 'also', 'assumed', 'compressible', 'laminar', 'turbulent', 'boundary', 'layers', 'flow', 'immediate', 'vicinity', 'wall', 'laminar', 'sublayer', 'affected', 'region', 'heated', 'element', '.', 'assumption', 'permits', 'use', 'laminar', 'boundary-layer', 'equations', 'governing', 'equations', 'analysis', 'laminar', 'turbulent', 'boundary', 'layers', '.']\n",
      "\n",
      "Removed Punctuations\n",
      "-----------------\n",
      "['calculation', 'wall', 'shearing', 'stress', 'heattransfer', 'measurements', 'compressible', 'flows', '', 'shown', 'ludwieg', 'wall', 'shearing', 'stress', 'laminar', 'turbulent', 'boundary', 'layer', 'incompressible', 'flow', 'determined', 'heattransfer', 'measurement', 'surface', '', 'instrument', 'used', 'investigation', 'essentially', 'small', '', 'locally', 'insulated', '', 'heating', 'element', 'embedded', 'test', 'surface', '', 'size', 'instrument', 'restricted', 'condition', 'thermal', 'boundary', 'layer', 'generated', 'heating', 'element', 'contained', 'locally', 'within', 'laminar', 'sublayer', '', 'present', 'analysis', 'ludweig', 's', 'theory', 'instrument', 'extended', 'compressible', 'flow', 'insulated', 'flat', 'plate', '', 'limitations', 'design', 'operation', 'instrument', 'mentioned', '', 'also', 'assumed', 'compressible', 'laminar', 'turbulent', 'boundary', 'layers', 'flow', 'immediate', 'vicinity', 'wall', 'laminar', 'sublayer', 'affected', 'region', 'heated', 'element', '', 'assumption', 'permits', 'use', 'laminar', 'boundarylayer', 'equations', 'governing', 'equations', 'analysis', 'laminar', 'turbulent', 'boundary', 'layers', '']\n",
      "\n",
      "Removed Blankspaces\n",
      "-----------------\n",
      "['calculation', 'wall', 'shearing', 'stress', 'heattransfer', 'measurements', 'compressible', 'flows', 'shown', 'ludwieg', 'wall', 'shearing', 'stress', 'laminar', 'turbulent', 'boundary', 'layer', 'incompressible', 'flow', 'determined', 'heattransfer', 'measurement', 'surface', 'instrument', 'used', 'investigation', 'essentially', 'small', 'locally', 'insulated', 'heating', 'element', 'embedded', 'test', 'surface', 'size', 'instrument', 'restricted', 'condition', 'thermal', 'boundary', 'layer', 'generated', 'heating', 'element', 'contained', 'locally', 'within', 'laminar', 'sublayer', 'present', 'analysis', 'ludweig', 's', 'theory', 'instrument', 'extended', 'compressible', 'flow', 'insulated', 'flat', 'plate', 'limitations', 'design', 'operation', 'instrument', 'mentioned', 'also', 'assumed', 'compressible', 'laminar', 'turbulent', 'boundary', 'layers', 'flow', 'immediate', 'vicinity', 'wall', 'laminar', 'sublayer', 'affected', 'region', 'heated', 'element', 'assumption', 'permits', 'use', 'laminar', 'boundarylayer', 'equations', 'governing', 'equations', 'analysis', 'laminar', 'turbulent', 'boundary', 'layers']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "proc_text = {}  # Storing the processed text\n",
    "\n",
    "# Converting the passed text to lower case\n",
    "def to_lower(text):\n",
    "    new_text = text.lower()\n",
    "    new_text = contractions.fix(new_text)  # contractions library is used to remove the contracted form of words. Eg - \"I'll\" will be converted to \"I will\" etc.\n",
    "    return new_text\n",
    "\n",
    "# Tokenizing the passed text\n",
    "def tokenize(text):\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "# Removing stop words from the tokens passed. Eg - a, an, the, and etc.\n",
    "def remove_stopwords(tokens):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    res = []\n",
    "    for word in tokens:\n",
    "        if word not in stop_words:\n",
    "            res.append(word)\n",
    "    return res\n",
    "\n",
    "# Removing the punctuations from the tokens passed by iterating on a character level. Eg - . , ! - etc.\n",
    "def remove_punc(tokens):\n",
    "    punctuations = string.punctuation\n",
    "    res = []\n",
    "    for word in tokens:\n",
    "        new_word = \"\"\n",
    "        for character in word:\n",
    "            if character not in punctuations:\n",
    "                new_word += character\n",
    "        res.append(new_word)\n",
    "    \n",
    "    return res\n",
    "\n",
    "# Removing blank space characters (\"\") if any from the passed tokens \n",
    "def remove_blank(tokens):\n",
    "    res = []\n",
    "    for word in tokens:\n",
    "        if word != \"\":\n",
    "            res.append(word)\n",
    "            \n",
    "    return res\n",
    "\n",
    "def print_text(text, i, operation):\n",
    "    if i < 5:\n",
    "        print(operation)\n",
    "        print(\"-----------------\")\n",
    "        print(text)\n",
    "        print()\n",
    "\n",
    "i = 0\n",
    "# Performing the above defined preprocessing steps for all the file of the above dataset\n",
    "for key in req_text.keys():\n",
    "    text = req_text[key]\n",
    "    print_text(text, i, \"Original Text\")\n",
    "    text = to_lower(text)  # Lower casing the text\n",
    "    print_text(text, i, \"To lowercase\")\n",
    "    text = tokenize(text)  # Tokenizing\n",
    "    print_text(text, i, \"Tokenized Text\")\n",
    "    text = remove_stopwords(text)  # Removing stop words\n",
    "    print_text(text, i, \"Removed Stopwords\")\n",
    "    text = remove_punc(text)  # Removing punctuation marks\n",
    "    print_text(text, i, \"Removed Punctuations\")\n",
    "    text = remove_blank(text)  # Removing blank spaces\n",
    "    print_text(text, i, \"Removed Blankspaces\")\n",
    "    \n",
    "    i += 1\n",
    "    proc_text[key] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "845c2a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127208\n",
      "8990\n",
      "originates\n",
      "originates\n"
     ]
    }
   ],
   "source": [
    "# Storing the total unique words throught the complete document dataset and assigning them unique term ids\n",
    "vocabulary = []\n",
    "id_to_term = {}\n",
    "\n",
    "for doc in proc_text.keys():\n",
    "    for word in proc_text[doc]:\n",
    "        vocabulary.append(word)\n",
    "\n",
    "print(len(vocabulary))\n",
    "vocabulary = list(set(vocabulary))\n",
    "print(len(vocabulary))\n",
    "\n",
    "for i, term in enumerate(vocabulary):\n",
    "    id_to_term[i] = term\n",
    "    \n",
    "\n",
    "k = 10\n",
    "print(id_to_term[k])\n",
    "print(vocabulary[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2afbb1d",
   "metadata": {},
   "source": [
    "# TF-IDF Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "925ff121",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_schemes = ['binary', 'raw_count', 'term_frequency', 'log_normal', 'double_normal'] # All different weighting schemes for tf weights\n",
    "\n",
    "# Computing the frequencies of all unique terms in the dataset\n",
    "def raw_term_frequency():\n",
    "    rtf = {}\n",
    "    for i in range(len(proc_text)):\n",
    "        rtf[i] = {}\n",
    "        unique_words, freq = np.unique(proc_text[doc_id_to_name[i]], return_counts = True)\n",
    "        for j in range(len(unique_words)):\n",
    "            rtf[i][unique_words[j]] = freq[j]\n",
    "    \n",
    "    return rtf\n",
    "\n",
    "# Posting list for all the terms Eg - ('experiment' = [1, 2, 16, ...], ...)\n",
    "def postings_list():\n",
    "    post_list = {}\n",
    "    for i in range(len(proc_text)):\n",
    "        words = np.unique(proc_text[doc_id_to_name[i]])\n",
    "        for word in words:\n",
    "            if word not in post_list.keys():\n",
    "                post_list[word] = [i]\n",
    "            else:\n",
    "                if i not in post_list[word]:\n",
    "                    post_list[word].append(i)\n",
    "                \n",
    "    return post_list\n",
    "\n",
    "# Computing the idf score for each term after getting the postings list\n",
    "# idf score of term = log10(total number of documents / document frequency(term) + 1)\n",
    "def compute_idf(post_list):\n",
    "    idf = {}\n",
    "    for term in post_list.keys():\n",
    "        idf[term] = math.log10(len(proc_text) / (len(post_list[term]) + 1))\n",
    "        \n",
    "    return idf\n",
    "\n",
    "# Computing the term frequency weights of all terms for all the documents\n",
    "# Weighting schemes = ['Binary', 'Raw count', 'Term frequency', 'Log normalization', 'Double normalization']\n",
    "def compute_tf_weight(scheme, term, doc_tf):\n",
    "    # Return 1 if term found in document else 0\n",
    "    if scheme == \"binary\":\n",
    "        if term in doc_tf.keys():\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    # Return raw count of term in document  \n",
    "    if scheme == \"raw_count\":\n",
    "        if term in doc_tf.keys():\n",
    "            return doc_tf[term]\n",
    "        else:\n",
    "            return 0\n",
    "    # Return frequency of term in document / total length of documents tokens\n",
    "    if scheme == \"term_frequency\":\n",
    "        if term in doc_tf.keys():\n",
    "            return doc_tf[term] / sum(doc_tf.values())\n",
    "        else:\n",
    "            return 0\n",
    "    # Return log10(1 + frequency of term in document)\n",
    "    if scheme == \"log_normal\":\n",
    "        if term in doc_tf.keys():\n",
    "            return math.log10(1 + doc_tf[term])\n",
    "        else:\n",
    "            return 0\n",
    "    # Return 0.5(1 + frequency of term in document / max frequency of vocabulary in document dataset)\n",
    "    if scheme == \"double_normal\":\n",
    "        if term in doc_tf.keys():\n",
    "            return 0.5 + 0.5 * doc_tf[term] / max(doc_tf.values())\n",
    "        else:\n",
    "            return 0.5\n",
    "        \n",
    "# Generating the tf_idf weights matrix \n",
    "def compute_tf_idf_matrix():\n",
    "    # Initialising the tf-idf matrix for all weighting schemes \n",
    "    tf_idf = {}\n",
    "    rtf = raw_term_frequency() # Fetching the raw frequencies for all the terms\n",
    "    post_list = postings_list() # Computing postings list for all the terms\n",
    "    term_idf = compute_idf(post_list) # Computing the idf scores for all the terms\n",
    "    for scheme in weight_schemes:\n",
    "        print(f'Computing weights for {scheme} scheme -> -> ->')\n",
    "        tf_idf[scheme] = {}\n",
    "        tf_idf[scheme] = np.zeros((len(proc_text), len(vocabulary))) # Declaring the numpy zeros array of dimensions (number of documents, number of terms in vocabulary)\n",
    "        for doc in tqdm(range(len(proc_text))):\n",
    "            for j in range(len(vocabulary)):\n",
    "                tf_weight = compute_tf_weight(scheme, vocabulary[j], rtf[doc]) # tf weight of term j in document i for the given scheme\n",
    "                idf = term_idf[vocabulary[j]] # idf score for term j\n",
    "                tf_idf[scheme][doc][j] = tf_weight * idf # Tf-idf score for term j in document i for given scheme\n",
    "    \n",
    "    return tf_idf\n",
    "\n",
    "# Preprocessing the query passed\n",
    "def query_preprocessing(text):\n",
    "    text = to_lower(text)  # Lower casing the text\n",
    "    text = tokenize(text)  # Tokenizing\n",
    "    text = remove_stopwords(text)  # Removing stop words\n",
    "    text = remove_punc(text)  # Removing punctuation marks\n",
    "    text = remove_blank(text)  # Removing blank spaces\n",
    "    return text\n",
    "\n",
    "# Computing the query vector for given query tokens\n",
    "def compute_query_vector(query_tokens):\n",
    "    query_vector = {}\n",
    "    query_tf = {} # Term frequencies for query tokens in document dataset\n",
    "    term_idf = compute_idf(postings_list()) # idf scores for terms\n",
    "    for term in query_tokens:\n",
    "        if term not in query_tf.keys():\n",
    "            query_tf[term] = 1\n",
    "        else:\n",
    "            query_tf[term] += 1\n",
    "    \n",
    "    print(query_tf)\n",
    "    for scheme in weight_schemes:\n",
    "        # Declaring query vector as numpy zeros of dimensions (length of vocabulary, 1)\n",
    "        query_vector[scheme] = np.zeros((len(vocabulary), 1)) \n",
    "        for i in range(len(vocabulary)):\n",
    "            tf_weight_ = compute_tf_weight(scheme, vocabulary[i], query_tf) # Assiging the required tf weight for ith vocabulary term\n",
    "            idf_ = term_idf[vocabulary[i]] if term in term_idf.keys() else 0\n",
    "            query_vector[scheme][i] = tf_weight_ * idf_ # Tf-idf score for qery token\n",
    "            \n",
    "    return query_vector\n",
    "\n",
    "# Generate results for the query passed for all weighting schemes and return top 5 documents for each\n",
    "def solve_tf_idf_query(query, tf_idf):\n",
    "    query_tokens = query_preprocessing(query) # Generating query tokens \n",
    "    query_vector = compute_query_vector(query_tokens) # Compute query vector for the processed query\n",
    "    print(query) \n",
    "    print(query_tokens)\n",
    "    print()\n",
    "    \n",
    "    for scheme in weight_schemes:\n",
    "        print(f\"Results for scheme : {scheme}\")\n",
    "        tf_mat = tf_idf[scheme] # Tf-idf matrix for the given scheme\n",
    "        query_vec = query_vector[scheme] # Getting the query vector for the given scheme\n",
    "        mult = np.dot(tf_mat, query_vec).reshape(len(proc_text)) # Getting the matrix multiplication for tf-idf matrix and query vector\n",
    "        ans = (-mult).argsort()[:5] # Getting the documents with top 5 scores\n",
    "        for ind in range(len(ans)):\n",
    "            print(doc_id_to_name[ans[ind]], end = \" \") # Priting the document names and scores for the best 5 documents\n",
    "        print()\n",
    "        vals = []\n",
    "        for idx in ans:\n",
    "            vals.append(mult[idx])\n",
    "        print(vals)\n",
    "        print()\n",
    "        print(\"----------------------\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b8a5980",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing weights for binary scheme -> -> ->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1400/1400 [00:08<00:00, 160.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing weights for raw_count scheme -> -> ->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1400/1400 [00:08<00:00, 157.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing weights for term_frequency scheme -> -> ->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1400/1400 [00:08<00:00, 155.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing weights for log_normal scheme -> -> ->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1400/1400 [00:09<00:00, 146.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing weights for double_normal scheme -> -> ->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1400/1400 [00:10<00:00, 138.60it/s]\n"
     ]
    }
   ],
   "source": [
    "tf_idf = compute_tf_idf_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e96938b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for scheme in weight_schemes:\n",
    "    pickle.dump(tf_idf[scheme], open(f\"{scheme}_tf_idf.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fa02819",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = {}\n",
    "for scheme in weight_schemes:\n",
    "    tf_idf[scheme] = pickle.load(open(f\"{scheme}_tf_idf.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4b1900a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(tf_idf['binary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b2131ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experimental': 1, 'design': 1, 'aerodynamic': 1, 'flows': 1}\n",
      "Experimental design of aerodynamic flows\n",
      "['experimental', 'design', 'aerodynamic', 'flows']\n",
      "\n",
      "Results for scheme : binary\n",
      "cranfield0415 cranfield0964 cranfield0986 cranfield0753 cranfield0277 \n",
      "[3.0549800880863303, 2.57339261190454, 2.57339261190454, 2.452190373072495, 2.452190373072495]\n",
      "\n",
      "----------------------\n",
      "\n",
      "Results for scheme : raw_count\n",
      "cranfield1066 cranfield0198 cranfield0332 cranfield0640 cranfield0415 \n",
      "[8.911538233068093, 7.968628163321502, 7.132324062553562, 6.830252711418431, 6.22943219056808]\n",
      "\n",
      "----------------------\n",
      "\n",
      "Results for scheme : term_frequency\n",
      "cranfield0834 cranfield0415 cranfield0137 cranfield0706 cranfield1293 \n",
      "[0.03162154033064088, 0.023959354579108003, 0.023036626248385723, 0.017875498903643015, 0.017787116435985496]\n",
      "\n",
      "----------------------\n",
      "\n",
      "Results for scheme : log_normal\n",
      "cranfield0415 cranfield0986 cranfield0658 cranfield1195 cranfield0712 \n",
      "[0.42758394937482386, 0.3740647602048351, 0.3523885229443796, 0.3334450983031201, 0.3301450624399292]\n",
      "\n",
      "----------------------\n",
      "\n",
      "Results for scheme : double_normal\n",
      "cranfield0718 cranfield0212 cranfield1167 cranfield0344 cranfield0489 \n",
      "[14663.03031162913, 14651.176266637563, 14646.61314279648, 14646.49135716969, 14645.443205709305]\n",
      "\n",
      "----------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "solve_tf_idf_query(\"Experimental design of aerodynamic flows\", tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a848892b",
   "metadata": {},
   "source": [
    "# Jacardian Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dccaad6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Intersection for query tokens and document tokens\n",
    "def intersection(query_tokens, doc_tokens):\n",
    "    return len(list(set(query_tokens) & set(doc_tokens)))\n",
    "\n",
    "# Union for query tokens and document tokens\n",
    "def union(query_tokens, doc_tokens):\n",
    "    return len(list(set(query_tokens) | set(doc_tokens)))\n",
    "\n",
    "# Gererating jacardian coefficient results for the given query\n",
    "def solve_jacardian_query(query):\n",
    "    query_tokens = query_preprocessing(query) # Getting query tokens\n",
    "    print(query_tokens)\n",
    "    print()\n",
    "    coeff = [0] * len(proc_text) # Jacardian Coefficient array for all the documents\n",
    "    for i in range(len(coeff)):\n",
    "        intersection_ = intersection(query_tokens, proc_text[doc_id_to_name[i]]) # Number of intersections for query tokens and document tokens\n",
    "        union_ = union(query_tokens, proc_text[doc_id_to_name[i]]) # Number of unions for query tokens and document tokens\n",
    "        coeff[i] =  intersection_ / union_ # Jacardian coefficient for given query and document dataset\n",
    "    coeff = np.array(coeff)\n",
    "    ans = (-coeff).argsort()[:5] # Getting the top 5 documents with highest scores\n",
    "    for ind in range(len(ans)): # Printing details of these 5 best documents\n",
    "        print(doc_id_to_name[ans[ind]], end = \" \")\n",
    "    print()\n",
    "    vals = []\n",
    "    for idx in ans:\n",
    "        vals.append(coeff[idx])\n",
    "    print(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca2c7e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['experimental', 'design', 'experimental', 'flows']\n",
      "\n",
      "cranfield1045 cranfield0418 cranfield0935 cranfield1069 cranfield0203 \n",
      "[0.06666666666666667, 0.0625, 0.0625, 0.06060606060606061, 0.05714285714285714]\n"
     ]
    }
   ],
   "source": [
    "solve_jacardian_query(\"Experimental design of experimental flows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09b0e8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 0 -> TF-IDF Query\n",
      "Enter 1 -> Jacardian Query\n",
      "Enter Query\n",
      "{'1': 1}\n",
      "1\n",
      "['1']\n",
      "\n",
      "Results for scheme : binary\n",
      "cranfield0401 cranfield1201 cranfield0362 cranfield0064 cranfield0131 \n",
      "[0.8479071776304049, 0.8479071776304049, 0.8479071776304049, 0.8479071776304049, 0.8479071776304049]\n",
      "\n",
      "----------------------\n",
      "\n",
      "Results for scheme : raw_count\n",
      "cranfield0917 cranfield0095 cranfield0213 cranfield0654 cranfield0903 \n",
      "[3.3916287105216196, 2.543721532891215, 2.543721532891215, 2.543721532891215, 2.543721532891215]\n",
      "\n",
      "----------------------\n",
      "\n",
      "Results for scheme : term_frequency\n",
      "cranfield1299 cranfield0654 cranfield0095 cranfield0271 cranfield0528 \n",
      "[0.043482419365661794, 0.042395358881520254, 0.042395358881520254, 0.036865529462191515, 0.033470020169621244]\n",
      "\n",
      "----------------------\n",
      "\n",
      "Results for scheme : log_normal\n",
      "cranfield0917 cranfield0095 cranfield0213 cranfield0654 cranfield0903 \n",
      "[0.1784089440518011, 0.1536730999074765, 0.1536730999074765, 0.1536730999074765, 0.1536730999074765]\n",
      "\n",
      "----------------------\n",
      "\n",
      "Results for scheme : double_normal\n",
      "cranfield0718 cranfield0212 cranfield1167 cranfield0344 cranfield0489 \n",
      "[14662.374514970894, 14650.209869008695, 14645.9226699947, 14645.836213833647, 14644.66004612138]\n",
      "\n",
      "----------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Main function for running question 1\n",
    "def main():\n",
    "    print(\"Enter 0 -> TF-IDF Query\")\n",
    "    print(\"Enter 1 -> Jacardian Query\")\n",
    "    n = int(input())\n",
    "    print(\"Enter Query\")\n",
    "    query = str(input())\n",
    "    if query == \"\":\n",
    "        print(\"Empty query\")\n",
    "        return\n",
    "    if n == 0:\n",
    "        solve_tf_idf_query(query, tf_idf)\n",
    "    else:\n",
    "        solve_jacardian_query(query)\n",
    "\n",
    "main()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cee32d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
