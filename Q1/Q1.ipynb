{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0fe432c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in c:\\users\\moksh\\anaconda3\\lib\\site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in c:\\users\\moksh\\anaconda3\\lib\\site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\moksh\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n",
      "Requirement already satisfied: anyascii in c:\\users\\moksh\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Moksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "!pip install contractions\n",
    "import contractions\n",
    "import pickle\n",
    "nltk.download('stopwords')\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692b0ee3",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52bc8093",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 365243.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1400/1400 [00:23<00:00, 59.60it/s]\n"
     ]
    }
   ],
   "source": [
    "path = \"../data/CSE508_Winter2023_Dataset\"\n",
    "dir_ = os.listdir(path)\n",
    "doc_id_to_name = {}  # Mapping doc_id numbers to the documents names\n",
    "file_data = {}  # Document data according to document name\n",
    "\n",
    "for i in tqdm(range(len(dir_))):\n",
    "    doc_id_to_name[i] = dir_[i]\n",
    "\n",
    "for i in tqdm(range(len(dir_))):\n",
    "    with open(f'{path}/{dir_[i]}') as f:\n",
    "        contents = f.read()\n",
    "        file_data[dir_[i]] = contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a75f0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cranfield0035'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_id_to_name[34]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80d7690",
   "metadata": {},
   "source": [
    "# Extracting Relevant Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eebcfda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "req_text = {}  # Required data between these mentioned tags\n",
    "\n",
    "for key in file_data.keys():\n",
    "    text = file_data[key]\n",
    "    \n",
    "    soup = BeautifulSoup(text, 'html.parser')  # Creating soup object and passing it the text file\n",
    "    title_tag = soup.find('title')  # Searching for TITLE tag in the document\n",
    "    text_tag = soup.find('text')  # Searching for TEXT tag in the document\n",
    "    \n",
    "    title_data = \"\"\n",
    "    text_data = \"\"\n",
    "    \n",
    "    if title_tag:\n",
    "        title_data = title_tag.text  # If TITLE tag is found updating the title data otherwise it is empty\n",
    "    \n",
    "    if text_tag:\n",
    "        text_data = text_tag.text  # If TEXT tag is found updating the text data otherwise it is empty\n",
    "        \n",
    "    new_text = f'{title_data} {text_data}'  # Concatenating the data with a blank space\n",
    "    \n",
    "    req_text[key] = new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d771e7",
   "metadata": {},
   "source": [
    "**Printing for first 5 files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "906b28c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before !-------------------!\n",
      "\n",
      "<DOC>\n",
      "<DOCNO>\n",
      "1\n",
      "</DOCNO>\n",
      "<TITLE>\n",
      "experimental investigation of the aerodynamics of a\n",
      "wing in a slipstream .\n",
      "</TITLE>\n",
      "<AUTHOR>\n",
      "brenckman,m.\n",
      "</AUTHOR>\n",
      "<BIBLIO>\n",
      "j. ae. scs. 25, 1958, 324.\n",
      "</BIBLIO>\n",
      "<TEXT>\n",
      "  an experimental study of a wing in a propeller slipstream was\n",
      "made in order to determine the spanwise distribution of the lift\n",
      "increase due to slipstream at different angles of attack of the wing\n",
      "and at different free stream to slipstream velocity ratios .  the\n",
      "results were intended in part as an evaluation basis for different\n",
      "theoretical treatments of this problem .\n",
      "  the comparative span loading curves, together with supporting\n",
      "evidence, showed that a substantial part of the lift increment\n",
      "produced by the slipstream was due to a /destalling/ or boundary-layer-control\n",
      "effect .  the integrated remaining lift increment,\n",
      "after subtracting this destalling lift, was found to agree\n",
      "well with a potential flow theory .\n",
      "  an empirical evaluation of the destalling effects was made for\n",
      "the specific configuration of the experiment .\n",
      "</TEXT>\n",
      "</DOC>\n",
      "\n",
      "\n",
      "After  !-------------------!\n",
      "\n",
      "\n",
      "experimental investigation of the aerodynamics of a\n",
      "wing in a slipstream .\n",
      " \n",
      "  an experimental study of a wing in a propeller slipstream was\n",
      "made in order to determine the spanwise distribution of the lift\n",
      "increase due to slipstream at different angles of attack of the wing\n",
      "and at different free stream to slipstream velocity ratios .  the\n",
      "results were intended in part as an evaluation basis for different\n",
      "theoretical treatments of this problem .\n",
      "  the comparative span loading curves, together with supporting\n",
      "evidence, showed that a substantial part of the lift increment\n",
      "produced by the slipstream was due to a /destalling/ or boundary-layer-control\n",
      "effect .  the integrated remaining lift increment,\n",
      "after subtracting this destalling lift, was found to agree\n",
      "well with a potential flow theory .\n",
      "  an empirical evaluation of the destalling effects was made for\n",
      "the specific configuration of the experiment .\n",
      "\n",
      "\n",
      "Before !-------------------!\n",
      "\n",
      "<DOC>\n",
      "<DOCNO>\n",
      "2\n",
      "</DOCNO>\n",
      "<TITLE>\n",
      "simple shear flow past a flat plate in an incompressible fluid of small\n",
      "viscosity .\n",
      "</TITLE>\n",
      "<AUTHOR>\n",
      "ting-yili\n",
      "</AUTHOR>\n",
      "<BIBLIO>\n",
      "department of aeronautical engineering, rensselaer polytechnic\n",
      "institute\n",
      "troy, n.y.\n",
      "</BIBLIO>\n",
      "<TEXT>\n",
      "in the study of high-speed viscous flow past a two-dimensional body it\n",
      "is usually necessary to consider a curved shock wave emitting from the\n",
      "nose or leading edge of the body .  consequently, there exists an inviscid\n",
      "rotational flow region between the shock wave and the boundary layer\n",
      ".  such a situation arises, for instance, in the study of the hypersonic\n",
      "viscous flow past a flat plate .  the situation is somewhat different\n",
      "from prandtl's classical boundary-layer problem . in prandtl's\n",
      "original problem the inviscid free stream outside the boundary layer is\n",
      "irrotational while in a hypersonic boundary-layer problem the inviscid\n",
      "free stream must be considered as rotational .  the possible effects of\n",
      "vorticity have been recently discussed by ferri and libby .  in the present\n",
      "paper, the simple shear flow past a flat plate in a fluid of small\n",
      "viscosity is investigated .  it can be shown that this problem can again\n",
      "be treated by the boundary-layer approximation, the only novel feature\n",
      "being that the free stream has a constant vorticity .  the discussion\n",
      "here is restricted to two-dimensional incompressible steady flow .\n",
      "</TEXT>\n",
      "</DOC>\n",
      "\n",
      "\n",
      "After  !-------------------!\n",
      "\n",
      "\n",
      "simple shear flow past a flat plate in an incompressible fluid of small\n",
      "viscosity .\n",
      " \n",
      "in the study of high-speed viscous flow past a two-dimensional body it\n",
      "is usually necessary to consider a curved shock wave emitting from the\n",
      "nose or leading edge of the body .  consequently, there exists an inviscid\n",
      "rotational flow region between the shock wave and the boundary layer\n",
      ".  such a situation arises, for instance, in the study of the hypersonic\n",
      "viscous flow past a flat plate .  the situation is somewhat different\n",
      "from prandtl's classical boundary-layer problem . in prandtl's\n",
      "original problem the inviscid free stream outside the boundary layer is\n",
      "irrotational while in a hypersonic boundary-layer problem the inviscid\n",
      "free stream must be considered as rotational .  the possible effects of\n",
      "vorticity have been recently discussed by ferri and libby .  in the present\n",
      "paper, the simple shear flow past a flat plate in a fluid of small\n",
      "viscosity is investigated .  it can be shown that this problem can again\n",
      "be treated by the boundary-layer approximation, the only novel feature\n",
      "being that the free stream has a constant vorticity .  the discussion\n",
      "here is restricted to two-dimensional incompressible steady flow .\n",
      "\n",
      "\n",
      "Before !-------------------!\n",
      "\n",
      "<DOC>\n",
      "<DOCNO>\n",
      "3\n",
      "</DOCNO>\n",
      "<TITLE>\n",
      "the boundary layer in simple shear flow past a flat plate .\n",
      "</TITLE>\n",
      "<AUTHOR>\n",
      "m. b. glauert\n",
      "</AUTHOR>\n",
      "<BIBLIO>\n",
      "department of mathematics, university of manchester, manchester,\n",
      "england\n",
      "</BIBLIO>\n",
      "<TEXT>\n",
      "the boundary-layer equations are presented for steady\n",
      "incompressible flow with no pressure gradient .\n",
      "</TEXT>\n",
      "</DOC>\n",
      "\n",
      "\n",
      "After  !-------------------!\n",
      "\n",
      "\n",
      "the boundary layer in simple shear flow past a flat plate .\n",
      " \n",
      "the boundary-layer equations are presented for steady\n",
      "incompressible flow with no pressure gradient .\n",
      "\n",
      "\n",
      "Before !-------------------!\n",
      "\n",
      "<DOC>\n",
      "<DOCNO>\n",
      "4\n",
      "</DOCNO>\n",
      "<TITLE>\n",
      "approximate solutions of the incompressible laminar\n",
      "boundary layer equations for a plate in shear flow .\n",
      "</TITLE>\n",
      "<AUTHOR>\n",
      "yen,k.t.\n",
      "</AUTHOR>\n",
      "<BIBLIO>\n",
      "j. ae. scs. 22, 1955, 728.\n",
      "</BIBLIO>\n",
      "<TEXT>\n",
      "  the two-dimensional steady boundary-layer\n",
      "problem for a flat plate in a\n",
      "shear flow of incompressible fluid is considered .\n",
      "solutions for the boundarylayer\n",
      "thickness, skin friction, and the velocity\n",
      "distribution in the boundary\n",
      "layer are obtained by the karman-pohlhausen\n",
      "technique .  comparison with\n",
      "the boundary layer of a uniform flow has also\n",
      "been made to show the effect of\n",
      "vorticity .\n",
      "</TEXT>\n",
      "</DOC>\n",
      "\n",
      "\n",
      "After  !-------------------!\n",
      "\n",
      "\n",
      "approximate solutions of the incompressible laminar\n",
      "boundary layer equations for a plate in shear flow .\n",
      " \n",
      "  the two-dimensional steady boundary-layer\n",
      "problem for a flat plate in a\n",
      "shear flow of incompressible fluid is considered .\n",
      "solutions for the boundarylayer\n",
      "thickness, skin friction, and the velocity\n",
      "distribution in the boundary\n",
      "layer are obtained by the karman-pohlhausen\n",
      "technique .  comparison with\n",
      "the boundary layer of a uniform flow has also\n",
      "been made to show the effect of\n",
      "vorticity .\n",
      "\n",
      "\n",
      "Before !-------------------!\n",
      "\n",
      "<DOC>\n",
      "<DOCNO>\n",
      "5\n",
      "</DOCNO>\n",
      "<TITLE>\n",
      "one-dimensional transient heat conduction into a double-layer\n",
      "slab subjected to a linear heat input for a small time\n",
      "internal .\n",
      "</TITLE>\n",
      "<AUTHOR>\n",
      "wasserman,b.\n",
      "</AUTHOR>\n",
      "<BIBLIO>\n",
      "j. ae. scs. 24, 1957, 924.\n",
      "</BIBLIO>\n",
      "<TEXT>\n",
      "  analytic solutions are presented for the transient heat conduction\n",
      "in composite slabs exposed at one surface to a\n",
      "triangular heat rate .  this type of heating rate may occur, for\n",
      "example, during aerodynamic heating .\n",
      "</TEXT>\n",
      "</DOC>\n",
      "\n",
      "\n",
      "After  !-------------------!\n",
      "\n",
      "\n",
      "one-dimensional transient heat conduction into a double-layer\n",
      "slab subjected to a linear heat input for a small time\n",
      "internal .\n",
      " \n",
      "  analytic solutions are presented for the transient heat conduction\n",
      "in composite slabs exposed at one surface to a\n",
      "triangular heat rate .  this type of heating rate may occur, for\n",
      "example, during aerodynamic heating .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the content for first 5 files before and after relevant extraction\n",
    "for i in range(5):\n",
    "    print(\"Before !-------------------!\")\n",
    "    print()\n",
    "    print(file_data[doc_id_to_name[i]])\n",
    "    print()\n",
    "    print(\"After  !-------------------!\")\n",
    "    print()\n",
    "    print(req_text[doc_id_to_name[i]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deee8fe1",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5688df5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text\n",
      "-----------------\n",
      "\n",
      "experimental investigation of the aerodynamics of a\n",
      "wing in a slipstream .\n",
      " \n",
      "  an experimental study of a wing in a propeller slipstream was\n",
      "made in order to determine the spanwise distribution of the lift\n",
      "increase due to slipstream at different angles of attack of the wing\n",
      "and at different free stream to slipstream velocity ratios .  the\n",
      "results were intended in part as an evaluation basis for different\n",
      "theoretical treatments of this problem .\n",
      "  the comparative span loading curves, together with supporting\n",
      "evidence, showed that a substantial part of the lift increment\n",
      "produced by the slipstream was due to a /destalling/ or boundary-layer-control\n",
      "effect .  the integrated remaining lift increment,\n",
      "after subtracting this destalling lift, was found to agree\n",
      "well with a potential flow theory .\n",
      "  an empirical evaluation of the destalling effects was made for\n",
      "the specific configuration of the experiment .\n",
      "\n",
      "\n",
      "To lowercase\n",
      "-----------------\n",
      "\n",
      "experimental investigation of the aerodynamics of a\n",
      "wing in a slipstream .\n",
      " \n",
      "  an experimental study of a wing in a propeller slipstream was\n",
      "made in order to determine the spanwise distribution of the lift\n",
      "increase due to slipstream at different angles of attack of the wing\n",
      "and at different free stream to slipstream velocity ratios .  the\n",
      "results were intended in part as an evaluation basis for different\n",
      "theoretical treatments of this problem .\n",
      "  the comparative span loading curves, together with supporting\n",
      "evidence, showed that a substantial part of the lift increment\n",
      "produced by the slipstream was due to a /destalling/ or boundary-layer-control\n",
      "effect .  the integrated remaining lift increment,\n",
      "after subtracting this destalling lift, was found to agree\n",
      "well with a potential flow theory .\n",
      "  an empirical evaluation of the destalling effects was made for\n",
      "the specific configuration of the experiment .\n",
      "\n",
      "\n",
      "Tokenized Text\n",
      "-----------------\n",
      "['experimental', 'investigation', 'of', 'the', 'aerodynamics', 'of', 'a', 'wing', 'in', 'a', 'slipstream', '.', 'an', 'experimental', 'study', 'of', 'a', 'wing', 'in', 'a', 'propeller', 'slipstream', 'was', 'made', 'in', 'order', 'to', 'determine', 'the', 'spanwise', 'distribution', 'of', 'the', 'lift', 'increase', 'due', 'to', 'slipstream', 'at', 'different', 'angles', 'of', 'attack', 'of', 'the', 'wing', 'and', 'at', 'different', 'free', 'stream', 'to', 'slipstream', 'velocity', 'ratios', '.', 'the', 'results', 'were', 'intended', 'in', 'part', 'as', 'an', 'evaluation', 'basis', 'for', 'different', 'theoretical', 'treatments', 'of', 'this', 'problem', '.', 'the', 'comparative', 'span', 'loading', 'curves', ',', 'together', 'with', 'supporting', 'evidence', ',', 'showed', 'that', 'a', 'substantial', 'part', 'of', 'the', 'lift', 'increment', 'produced', 'by', 'the', 'slipstream', 'was', 'due', 'to', 'a', '/destalling/', 'or', 'boundary-layer-control', 'effect', '.', 'the', 'integrated', 'remaining', 'lift', 'increment', ',', 'after', 'subtracting', 'this', 'destalling', 'lift', ',', 'was', 'found', 'to', 'agree', 'well', 'with', 'a', 'potential', 'flow', 'theory', '.', 'an', 'empirical', 'evaluation', 'of', 'the', 'destalling', 'effects', 'was', 'made', 'for', 'the', 'specific', 'configuration', 'of', 'the', 'experiment', '.']\n",
      "\n",
      "Removed Stopwords\n",
      "-----------------\n",
      "['experimental', 'investigation', 'aerodynamics', 'wing', 'slipstream', '.', 'experimental', 'study', 'wing', 'propeller', 'slipstream', 'made', 'order', 'determine', 'spanwise', 'distribution', 'lift', 'increase', 'due', 'slipstream', 'different', 'angles', 'attack', 'wing', 'different', 'free', 'stream', 'slipstream', 'velocity', 'ratios', '.', 'results', 'intended', 'part', 'evaluation', 'basis', 'different', 'theoretical', 'treatments', 'problem', '.', 'comparative', 'span', 'loading', 'curves', ',', 'together', 'supporting', 'evidence', ',', 'showed', 'substantial', 'part', 'lift', 'increment', 'produced', 'slipstream', 'due', '/destalling/', 'boundary-layer-control', 'effect', '.', 'integrated', 'remaining', 'lift', 'increment', ',', 'subtracting', 'destalling', 'lift', ',', 'found', 'agree', 'well', 'potential', 'flow', 'theory', '.', 'empirical', 'evaluation', 'destalling', 'effects', 'made', 'specific', 'configuration', 'experiment', '.']\n",
      "\n",
      "Removed Punctuations\n",
      "-----------------\n",
      "['experimental', 'investigation', 'aerodynamics', 'wing', 'slipstream', '', 'experimental', 'study', 'wing', 'propeller', 'slipstream', 'made', 'order', 'determine', 'spanwise', 'distribution', 'lift', 'increase', 'due', 'slipstream', 'different', 'angles', 'attack', 'wing', 'different', 'free', 'stream', 'slipstream', 'velocity', 'ratios', '', 'results', 'intended', 'part', 'evaluation', 'basis', 'different', 'theoretical', 'treatments', 'problem', '', 'comparative', 'span', 'loading', 'curves', '', 'together', 'supporting', 'evidence', '', 'showed', 'substantial', 'part', 'lift', 'increment', 'produced', 'slipstream', 'due', 'destalling', 'boundarylayercontrol', 'effect', '', 'integrated', 'remaining', 'lift', 'increment', '', 'subtracting', 'destalling', 'lift', '', 'found', 'agree', 'well', 'potential', 'flow', 'theory', '', 'empirical', 'evaluation', 'destalling', 'effects', 'made', 'specific', 'configuration', 'experiment', '']\n",
      "\n",
      "Removed Blankspaces\n",
      "-----------------\n",
      "['experimental', 'investigation', 'aerodynamics', 'wing', 'slipstream', 'experimental', 'study', 'wing', 'propeller', 'slipstream', 'made', 'order', 'determine', 'spanwise', 'distribution', 'lift', 'increase', 'due', 'slipstream', 'different', 'angles', 'attack', 'wing', 'different', 'free', 'stream', 'slipstream', 'velocity', 'ratios', 'results', 'intended', 'part', 'evaluation', 'basis', 'different', 'theoretical', 'treatments', 'problem', 'comparative', 'span', 'loading', 'curves', 'together', 'supporting', 'evidence', 'showed', 'substantial', 'part', 'lift', 'increment', 'produced', 'slipstream', 'due', 'destalling', 'boundarylayercontrol', 'effect', 'integrated', 'remaining', 'lift', 'increment', 'subtracting', 'destalling', 'lift', 'found', 'agree', 'well', 'potential', 'flow', 'theory', 'empirical', 'evaluation', 'destalling', 'effects', 'made', 'specific', 'configuration', 'experiment']\n",
      "\n",
      "Original Text\n",
      "-----------------\n",
      "\n",
      "simple shear flow past a flat plate in an incompressible fluid of small\n",
      "viscosity .\n",
      " \n",
      "in the study of high-speed viscous flow past a two-dimensional body it\n",
      "is usually necessary to consider a curved shock wave emitting from the\n",
      "nose or leading edge of the body .  consequently, there exists an inviscid\n",
      "rotational flow region between the shock wave and the boundary layer\n",
      ".  such a situation arises, for instance, in the study of the hypersonic\n",
      "viscous flow past a flat plate .  the situation is somewhat different\n",
      "from prandtl's classical boundary-layer problem . in prandtl's\n",
      "original problem the inviscid free stream outside the boundary layer is\n",
      "irrotational while in a hypersonic boundary-layer problem the inviscid\n",
      "free stream must be considered as rotational .  the possible effects of\n",
      "vorticity have been recently discussed by ferri and libby .  in the present\n",
      "paper, the simple shear flow past a flat plate in a fluid of small\n",
      "viscosity is investigated .  it can be shown that this problem can again\n",
      "be treated by the boundary-layer approximation, the only novel feature\n",
      "being that the free stream has a constant vorticity .  the discussion\n",
      "here is restricted to two-dimensional incompressible steady flow .\n",
      "\n",
      "\n",
      "To lowercase\n",
      "-----------------\n",
      "\n",
      "simple shear flow past a flat plate in an incompressible fluid of small\n",
      "viscosity .\n",
      " \n",
      "in the study of high-speed viscous flow past a two-dimensional body it\n",
      "is usually necessary to consider a curved shock wave emitting from the\n",
      "nose or leading edge of the body .  consequently, there exists an inviscid\n",
      "rotational flow region between the shock wave and the boundary layer\n",
      ".  such a situation arises, for instance, in the study of the hypersonic\n",
      "viscous flow past a flat plate .  the situation is somewhat different\n",
      "from prandtl's classical boundary-layer problem . in prandtl's\n",
      "original problem the inviscid free stream outside the boundary layer is\n",
      "irrotational while in a hypersonic boundary-layer problem the inviscid\n",
      "free stream must be considered as rotational .  the possible effects of\n",
      "vorticity have been recently discussed by ferri and libby .  in the present\n",
      "paper, the simple shear flow past a flat plate in a fluid of small\n",
      "viscosity is investigated .  it can be shown that this problem can again\n",
      "be treated by the boundary-layer approximation, the only novel feature\n",
      "being that the free stream has a constant vorticity .  the discussion\n",
      "here is restricted to two-dimensional incompressible steady flow .\n",
      "\n",
      "\n",
      "Tokenized Text\n",
      "-----------------\n",
      "['simple', 'shear', 'flow', 'past', 'a', 'flat', 'plate', 'in', 'an', 'incompressible', 'fluid', 'of', 'small', 'viscosity', '.', 'in', 'the', 'study', 'of', 'high-speed', 'viscous', 'flow', 'past', 'a', 'two-dimensional', 'body', 'it', 'is', 'usually', 'necessary', 'to', 'consider', 'a', 'curved', 'shock', 'wave', 'emitting', 'from', 'the', 'nose', 'or', 'leading', 'edge', 'of', 'the', 'body', '.', 'consequently', ',', 'there', 'exists', 'an', 'inviscid', 'rotational', 'flow', 'region', 'between', 'the', 'shock', 'wave', 'and', 'the', 'boundary', 'layer', '.', 'such', 'a', 'situation', 'arises', ',', 'for', 'instance', ',', 'in', 'the', 'study', 'of', 'the', 'hypersonic', 'viscous', 'flow', 'past', 'a', 'flat', 'plate', '.', 'the', 'situation', 'is', 'somewhat', 'different', 'from', 'prandtl', \"'s\", 'classical', 'boundary-layer', 'problem', '.', 'in', \"prandtl's\", 'original', 'problem', 'the', 'inviscid', 'free', 'stream', 'outside', 'the', 'boundary', 'layer', 'is', 'irrotational', 'while', 'in', 'a', 'hypersonic', 'boundary-layer', 'problem', 'the', 'inviscid', 'free', 'stream', 'must', 'be', 'considered', 'as', 'rotational', '.', 'the', 'possible', 'effects', 'of', 'vorticity', 'have', 'been', 'recently', 'discussed', 'by', 'ferri', 'and', 'libby', '.', 'in', 'the', 'present', 'paper', ',', 'the', 'simple', 'shear', 'flow', 'past', 'a', 'flat', 'plate', 'in', 'a', 'fluid', 'of', 'small', 'viscosity', 'is', 'investigated', '.', 'it', 'can', 'be', 'shown', 'that', 'this', 'problem', 'can', 'again', 'be', 'treated', 'by', 'the', 'boundary-layer', 'approximation', ',', 'the', 'only', 'novel', 'feature', 'being', 'that', 'the', 'free', 'stream', 'has', 'a', 'constant', 'vorticity', '.', 'the', 'discussion', 'here', 'is', 'restricted', 'to', 'two-dimensional', 'incompressible', 'steady', 'flow', '.']\n",
      "\n",
      "Removed Stopwords\n",
      "-----------------\n",
      "['simple', 'shear', 'flow', 'past', 'flat', 'plate', 'incompressible', 'fluid', 'small', 'viscosity', '.', 'study', 'high-speed', 'viscous', 'flow', 'past', 'two-dimensional', 'body', 'usually', 'necessary', 'consider', 'curved', 'shock', 'wave', 'emitting', 'nose', 'leading', 'edge', 'body', '.', 'consequently', ',', 'exists', 'inviscid', 'rotational', 'flow', 'region', 'shock', 'wave', 'boundary', 'layer', '.', 'situation', 'arises', ',', 'instance', ',', 'study', 'hypersonic', 'viscous', 'flow', 'past', 'flat', 'plate', '.', 'situation', 'somewhat', 'different', 'prandtl', \"'s\", 'classical', 'boundary-layer', 'problem', '.', \"prandtl's\", 'original', 'problem', 'inviscid', 'free', 'stream', 'outside', 'boundary', 'layer', 'irrotational', 'hypersonic', 'boundary-layer', 'problem', 'inviscid', 'free', 'stream', 'must', 'considered', 'rotational', '.', 'possible', 'effects', 'vorticity', 'recently', 'discussed', 'ferri', 'libby', '.', 'present', 'paper', ',', 'simple', 'shear', 'flow', 'past', 'flat', 'plate', 'fluid', 'small', 'viscosity', 'investigated', '.', 'shown', 'problem', 'treated', 'boundary-layer', 'approximation', ',', 'novel', 'feature', 'free', 'stream', 'constant', 'vorticity', '.', 'discussion', 'restricted', 'two-dimensional', 'incompressible', 'steady', 'flow', '.']\n",
      "\n",
      "Removed Punctuations\n",
      "-----------------\n",
      "['simple', 'shear', 'flow', 'past', 'flat', 'plate', 'incompressible', 'fluid', 'small', 'viscosity', '', 'study', 'highspeed', 'viscous', 'flow', 'past', 'twodimensional', 'body', 'usually', 'necessary', 'consider', 'curved', 'shock', 'wave', 'emitting', 'nose', 'leading', 'edge', 'body', '', 'consequently', '', 'exists', 'inviscid', 'rotational', 'flow', 'region', 'shock', 'wave', 'boundary', 'layer', '', 'situation', 'arises', '', 'instance', '', 'study', 'hypersonic', 'viscous', 'flow', 'past', 'flat', 'plate', '', 'situation', 'somewhat', 'different', 'prandtl', 's', 'classical', 'boundarylayer', 'problem', '', 'prandtls', 'original', 'problem', 'inviscid', 'free', 'stream', 'outside', 'boundary', 'layer', 'irrotational', 'hypersonic', 'boundarylayer', 'problem', 'inviscid', 'free', 'stream', 'must', 'considered', 'rotational', '', 'possible', 'effects', 'vorticity', 'recently', 'discussed', 'ferri', 'libby', '', 'present', 'paper', '', 'simple', 'shear', 'flow', 'past', 'flat', 'plate', 'fluid', 'small', 'viscosity', 'investigated', '', 'shown', 'problem', 'treated', 'boundarylayer', 'approximation', '', 'novel', 'feature', 'free', 'stream', 'constant', 'vorticity', '', 'discussion', 'restricted', 'twodimensional', 'incompressible', 'steady', 'flow', '']\n",
      "\n",
      "Removed Blankspaces\n",
      "-----------------\n",
      "['simple', 'shear', 'flow', 'past', 'flat', 'plate', 'incompressible', 'fluid', 'small', 'viscosity', 'study', 'highspeed', 'viscous', 'flow', 'past', 'twodimensional', 'body', 'usually', 'necessary', 'consider', 'curved', 'shock', 'wave', 'emitting', 'nose', 'leading', 'edge', 'body', 'consequently', 'exists', 'inviscid', 'rotational', 'flow', 'region', 'shock', 'wave', 'boundary', 'layer', 'situation', 'arises', 'instance', 'study', 'hypersonic', 'viscous', 'flow', 'past', 'flat', 'plate', 'situation', 'somewhat', 'different', 'prandtl', 's', 'classical', 'boundarylayer', 'problem', 'prandtls', 'original', 'problem', 'inviscid', 'free', 'stream', 'outside', 'boundary', 'layer', 'irrotational', 'hypersonic', 'boundarylayer', 'problem', 'inviscid', 'free', 'stream', 'must', 'considered', 'rotational', 'possible', 'effects', 'vorticity', 'recently', 'discussed', 'ferri', 'libby', 'present', 'paper', 'simple', 'shear', 'flow', 'past', 'flat', 'plate', 'fluid', 'small', 'viscosity', 'investigated', 'shown', 'problem', 'treated', 'boundarylayer', 'approximation', 'novel', 'feature', 'free', 'stream', 'constant', 'vorticity', 'discussion', 'restricted', 'twodimensional', 'incompressible', 'steady', 'flow']\n",
      "\n",
      "Original Text\n",
      "-----------------\n",
      "\n",
      "the boundary layer in simple shear flow past a flat plate .\n",
      " \n",
      "the boundary-layer equations are presented for steady\n",
      "incompressible flow with no pressure gradient .\n",
      "\n",
      "\n",
      "To lowercase\n",
      "-----------------\n",
      "\n",
      "the boundary layer in simple shear flow past a flat plate .\n",
      " \n",
      "the boundary-layer equations are presented for steady\n",
      "incompressible flow with no pressure gradient .\n",
      "\n",
      "\n",
      "Tokenized Text\n",
      "-----------------\n",
      "['the', 'boundary', 'layer', 'in', 'simple', 'shear', 'flow', 'past', 'a', 'flat', 'plate', '.', 'the', 'boundary-layer', 'equations', 'are', 'presented', 'for', 'steady', 'incompressible', 'flow', 'with', 'no', 'pressure', 'gradient', '.']\n",
      "\n",
      "Removed Stopwords\n",
      "-----------------\n",
      "['boundary', 'layer', 'simple', 'shear', 'flow', 'past', 'flat', 'plate', '.', 'boundary-layer', 'equations', 'presented', 'steady', 'incompressible', 'flow', 'pressure', 'gradient', '.']\n",
      "\n",
      "Removed Punctuations\n",
      "-----------------\n",
      "['boundary', 'layer', 'simple', 'shear', 'flow', 'past', 'flat', 'plate', '', 'boundarylayer', 'equations', 'presented', 'steady', 'incompressible', 'flow', 'pressure', 'gradient', '']\n",
      "\n",
      "Removed Blankspaces\n",
      "-----------------\n",
      "['boundary', 'layer', 'simple', 'shear', 'flow', 'past', 'flat', 'plate', 'boundarylayer', 'equations', 'presented', 'steady', 'incompressible', 'flow', 'pressure', 'gradient']\n",
      "\n",
      "Original Text\n",
      "-----------------\n",
      "\n",
      "approximate solutions of the incompressible laminar\n",
      "boundary layer equations for a plate in shear flow .\n",
      " \n",
      "  the two-dimensional steady boundary-layer\n",
      "problem for a flat plate in a\n",
      "shear flow of incompressible fluid is considered .\n",
      "solutions for the boundarylayer\n",
      "thickness, skin friction, and the velocity\n",
      "distribution in the boundary\n",
      "layer are obtained by the karman-pohlhausen\n",
      "technique .  comparison with\n",
      "the boundary layer of a uniform flow has also\n",
      "been made to show the effect of\n",
      "vorticity .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "To lowercase\n",
      "-----------------\n",
      "\n",
      "approximate solutions of the incompressible laminar\n",
      "boundary layer equations for a plate in shear flow .\n",
      " \n",
      "  the two-dimensional steady boundary-layer\n",
      "problem for a flat plate in a\n",
      "shear flow of incompressible fluid is considered .\n",
      "solutions for the boundarylayer\n",
      "thickness, skin friction, and the velocity\n",
      "distribution in the boundary\n",
      "layer are obtained by the karman-pohlhausen\n",
      "technique .  comparison with\n",
      "the boundary layer of a uniform flow has also\n",
      "been made to show the effect of\n",
      "vorticity .\n",
      "\n",
      "\n",
      "Tokenized Text\n",
      "-----------------\n",
      "['approximate', 'solutions', 'of', 'the', 'incompressible', 'laminar', 'boundary', 'layer', 'equations', 'for', 'a', 'plate', 'in', 'shear', 'flow', '.', 'the', 'two-dimensional', 'steady', 'boundary-layer', 'problem', 'for', 'a', 'flat', 'plate', 'in', 'a', 'shear', 'flow', 'of', 'incompressible', 'fluid', 'is', 'considered', '.', 'solutions', 'for', 'the', 'boundarylayer', 'thickness', ',', 'skin', 'friction', ',', 'and', 'the', 'velocity', 'distribution', 'in', 'the', 'boundary', 'layer', 'are', 'obtained', 'by', 'the', 'karman-pohlhausen', 'technique', '.', 'comparison', 'with', 'the', 'boundary', 'layer', 'of', 'a', 'uniform', 'flow', 'has', 'also', 'been', 'made', 'to', 'show', 'the', 'effect', 'of', 'vorticity', '.']\n",
      "\n",
      "Removed Stopwords\n",
      "-----------------\n",
      "['approximate', 'solutions', 'incompressible', 'laminar', 'boundary', 'layer', 'equations', 'plate', 'shear', 'flow', '.', 'two-dimensional', 'steady', 'boundary-layer', 'problem', 'flat', 'plate', 'shear', 'flow', 'incompressible', 'fluid', 'considered', '.', 'solutions', 'boundarylayer', 'thickness', ',', 'skin', 'friction', ',', 'velocity', 'distribution', 'boundary', 'layer', 'obtained', 'karman-pohlhausen', 'technique', '.', 'comparison', 'boundary', 'layer', 'uniform', 'flow', 'also', 'made', 'show', 'effect', 'vorticity', '.']\n",
      "\n",
      "Removed Punctuations\n",
      "-----------------\n",
      "['approximate', 'solutions', 'incompressible', 'laminar', 'boundary', 'layer', 'equations', 'plate', 'shear', 'flow', '', 'twodimensional', 'steady', 'boundarylayer', 'problem', 'flat', 'plate', 'shear', 'flow', 'incompressible', 'fluid', 'considered', '', 'solutions', 'boundarylayer', 'thickness', '', 'skin', 'friction', '', 'velocity', 'distribution', 'boundary', 'layer', 'obtained', 'karmanpohlhausen', 'technique', '', 'comparison', 'boundary', 'layer', 'uniform', 'flow', 'also', 'made', 'show', 'effect', 'vorticity', '']\n",
      "\n",
      "Removed Blankspaces\n",
      "-----------------\n",
      "['approximate', 'solutions', 'incompressible', 'laminar', 'boundary', 'layer', 'equations', 'plate', 'shear', 'flow', 'twodimensional', 'steady', 'boundarylayer', 'problem', 'flat', 'plate', 'shear', 'flow', 'incompressible', 'fluid', 'considered', 'solutions', 'boundarylayer', 'thickness', 'skin', 'friction', 'velocity', 'distribution', 'boundary', 'layer', 'obtained', 'karmanpohlhausen', 'technique', 'comparison', 'boundary', 'layer', 'uniform', 'flow', 'also', 'made', 'show', 'effect', 'vorticity']\n",
      "\n",
      "Original Text\n",
      "-----------------\n",
      "\n",
      "one-dimensional transient heat conduction into a double-layer\n",
      "slab subjected to a linear heat input for a small time\n",
      "internal .\n",
      " \n",
      "  analytic solutions are presented for the transient heat conduction\n",
      "in composite slabs exposed at one surface to a\n",
      "triangular heat rate .  this type of heating rate may occur, for\n",
      "example, during aerodynamic heating .\n",
      "\n",
      "\n",
      "To lowercase\n",
      "-----------------\n",
      "\n",
      "one-dimensional transient heat conduction into a double-layer\n",
      "slab subjected to a linear heat input for a small time\n",
      "internal .\n",
      " \n",
      "  analytic solutions are presented for the transient heat conduction\n",
      "in composite slabs exposed at one surface to a\n",
      "triangular heat rate .  this type of heating rate may occur, for\n",
      "example, during aerodynamic heating .\n",
      "\n",
      "\n",
      "Tokenized Text\n",
      "-----------------\n",
      "['one-dimensional', 'transient', 'heat', 'conduction', 'into', 'a', 'double-layer', 'slab', 'subjected', 'to', 'a', 'linear', 'heat', 'input', 'for', 'a', 'small', 'time', 'internal', '.', 'analytic', 'solutions', 'are', 'presented', 'for', 'the', 'transient', 'heat', 'conduction', 'in', 'composite', 'slabs', 'exposed', 'at', 'one', 'surface', 'to', 'a', 'triangular', 'heat', 'rate', '.', 'this', 'type', 'of', 'heating', 'rate', 'may', 'occur', ',', 'for', 'example', ',', 'during', 'aerodynamic', 'heating', '.']\n",
      "\n",
      "Removed Stopwords\n",
      "-----------------\n",
      "['one-dimensional', 'transient', 'heat', 'conduction', 'double-layer', 'slab', 'subjected', 'linear', 'heat', 'input', 'small', 'time', 'internal', '.', 'analytic', 'solutions', 'presented', 'transient', 'heat', 'conduction', 'composite', 'slabs', 'exposed', 'one', 'surface', 'triangular', 'heat', 'rate', '.', 'type', 'heating', 'rate', 'may', 'occur', ',', 'example', ',', 'aerodynamic', 'heating', '.']\n",
      "\n",
      "Removed Punctuations\n",
      "-----------------\n",
      "['onedimensional', 'transient', 'heat', 'conduction', 'doublelayer', 'slab', 'subjected', 'linear', 'heat', 'input', 'small', 'time', 'internal', '', 'analytic', 'solutions', 'presented', 'transient', 'heat', 'conduction', 'composite', 'slabs', 'exposed', 'one', 'surface', 'triangular', 'heat', 'rate', '', 'type', 'heating', 'rate', 'may', 'occur', '', 'example', '', 'aerodynamic', 'heating', '']\n",
      "\n",
      "Removed Blankspaces\n",
      "-----------------\n",
      "['onedimensional', 'transient', 'heat', 'conduction', 'doublelayer', 'slab', 'subjected', 'linear', 'heat', 'input', 'small', 'time', 'internal', 'analytic', 'solutions', 'presented', 'transient', 'heat', 'conduction', 'composite', 'slabs', 'exposed', 'one', 'surface', 'triangular', 'heat', 'rate', 'type', 'heating', 'rate', 'may', 'occur', 'example', 'aerodynamic', 'heating']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "proc_text = {}  # Storing the processed text\n",
    "\n",
    "# Converting the passed text to lower case\n",
    "def to_lower(text):\n",
    "    new_text = text.lower()\n",
    "    new_text = contractions.fix(new_text)  # contractions library is used to remove the contracted form of words. Eg - \"I'll\" will be converted to \"I will\" etc.\n",
    "    return new_text\n",
    "\n",
    "# Tokenizing the passed text\n",
    "def tokenize(text):\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "# Removing stop words from the tokens passed. Eg - a, an, the, and etc.\n",
    "def remove_stopwords(tokens):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    res = []\n",
    "    for word in tokens:\n",
    "        if word not in stop_words:\n",
    "            res.append(word)\n",
    "    return res\n",
    "\n",
    "# Removing the punctuations from the tokens passed by iterating on a character level. Eg - . , ! - etc.\n",
    "def remove_punc(tokens):\n",
    "    punctuations = string.punctuation\n",
    "    res = []\n",
    "    for word in tokens:\n",
    "        new_word = \"\"\n",
    "        for character in word:\n",
    "            if character not in punctuations:\n",
    "                new_word += character\n",
    "        res.append(new_word)\n",
    "    \n",
    "    return res\n",
    "\n",
    "# Removing blank space characters (\"\") if any from the passed tokens \n",
    "def remove_blank(tokens):\n",
    "    res = []\n",
    "    for word in tokens:\n",
    "        if word != \"\":\n",
    "            res.append(word)\n",
    "            \n",
    "    return res\n",
    "\n",
    "def print_text(text, i, operation):\n",
    "    if i < 5:\n",
    "        print(operation)\n",
    "        print(\"-----------------\")\n",
    "        print(text)\n",
    "        print()\n",
    "\n",
    "i = 0\n",
    "# Performing the above defined preprocessing steps for all the file of the above dataset\n",
    "for key in req_text.keys():\n",
    "    text = req_text[key]\n",
    "    print_text(text, i, \"Original Text\")\n",
    "    text = to_lower(text)  # Lower casing the text\n",
    "    print_text(text, i, \"To lowercase\")\n",
    "    text = tokenize(text)  # Tokenizing\n",
    "    print_text(text, i, \"Tokenized Text\")\n",
    "    text = remove_stopwords(text)  # Removing stop words\n",
    "    print_text(text, i, \"Removed Stopwords\")\n",
    "    text = remove_punc(text)  # Removing punctuation marks\n",
    "    print_text(text, i, \"Removed Punctuations\")\n",
    "    text = remove_blank(text)  # Removing blank spaces\n",
    "    print_text(text, i, \"Removed Blankspaces\")\n",
    "    \n",
    "    i += 1\n",
    "    proc_text[key] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "845c2a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127208\n",
      "8990\n",
      "threshold\n",
      "threshold\n"
     ]
    }
   ],
   "source": [
    "# Storing the total unique words throught the complete document dataset and assigning them unique term ids\n",
    "vocabulary = []\n",
    "id_to_term = {}\n",
    "\n",
    "for doc in proc_text.keys():\n",
    "    for word in proc_text[doc]:\n",
    "        vocabulary.append(word)\n",
    "\n",
    "print(len(vocabulary))\n",
    "vocabulary = list(set(vocabulary))\n",
    "print(len(vocabulary))\n",
    "\n",
    "for i, term in enumerate(vocabulary):\n",
    "    id_to_term[i] = term\n",
    "    \n",
    "\n",
    "k = 10\n",
    "print(id_to_term[k])\n",
    "print(vocabulary[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2afbb1d",
   "metadata": {},
   "source": [
    "# TF-IDF Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "925ff121",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_schemes = ['binary', 'raw_count', 'term_frequency', 'log_normal', 'double_normal'] # All different weighting schemes for tf weights\n",
    "\n",
    "# Computing the frequencies of all unique terms in the dataset\n",
    "def raw_term_frequency():\n",
    "    rtf = {}\n",
    "    for i in range(len(proc_text)):\n",
    "        rtf[i] = {}\n",
    "        unique_words, freq = np.unique(proc_text[doc_id_to_name[i]], return_counts = True)\n",
    "        for j in range(len(unique_words)):\n",
    "            rtf[i][unique_words[j]] = freq[j]\n",
    "    \n",
    "    return rtf\n",
    "\n",
    "# Posting list for all the terms Eg - ('experiment' = [1, 2, 16, ...], ...)\n",
    "def postings_list():\n",
    "    post_list = {}\n",
    "    for i in range(len(proc_text)):\n",
    "        words = np.unique(proc_text[doc_id_to_name[i]])\n",
    "        for word in words:\n",
    "            if word not in post_list.keys():\n",
    "                post_list[word] = [i]\n",
    "            else:\n",
    "                if i not in post_list[word]:\n",
    "                    post_list[word].append(i)\n",
    "                \n",
    "    return post_list\n",
    "\n",
    "# Computing the idf score for each term after getting the postings list\n",
    "# idf score of term = log10(total number of documents / document frequency(term) + 1)\n",
    "def compute_idf(post_list):\n",
    "    idf = {}\n",
    "    for term in post_list.keys():\n",
    "        idf[term] = math.log10(len(proc_text) / (len(post_list[term]) + 1))\n",
    "        \n",
    "    return idf\n",
    "\n",
    "# Computing the term frequency weights of all terms for all the documents\n",
    "# Weighting schemes = ['Binary', 'Raw count', 'Term frequency', 'Log normalization', 'Double normalization']\n",
    "def compute_tf_weight(scheme, term, doc_tf):\n",
    "    # Return 1 if term found in document else 0\n",
    "    if scheme == \"binary\":\n",
    "        if term in doc_tf.keys():\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    # Return raw count of term in document  \n",
    "    if scheme == \"raw_count\":\n",
    "        if term in doc_tf.keys():\n",
    "            return doc_tf[term]\n",
    "        else:\n",
    "            return 0\n",
    "    # Return frequency of term in document / total length of documents tokens\n",
    "    if scheme == \"term_frequency\":\n",
    "        if term in doc_tf.keys():\n",
    "            return doc_tf[term] / sum(doc_tf.values())\n",
    "        else:\n",
    "            return 0\n",
    "    # Return log10(1 + frequency of term in document)\n",
    "    if scheme == \"log_normal\":\n",
    "        if term in doc_tf.keys():\n",
    "            return math.log10(1 + doc_tf[term])\n",
    "        else:\n",
    "            return 0\n",
    "    # Return 0.5(1 + frequency of term in document / max frequency of vocabulary in document dataset)\n",
    "    if scheme == \"double_normal\":\n",
    "        if term in doc_tf.keys():\n",
    "            return 0.5 + 0.5 * doc_tf[term] / max(doc_tf.values())\n",
    "        else:\n",
    "            return 0.5\n",
    "        \n",
    "# Generating the tf_idf weights matrix \n",
    "def compute_tf_idf_matrix():\n",
    "    # Initialising the tf-idf matrix for all weighting schemes \n",
    "    tf_idf = {}\n",
    "    rtf = raw_term_frequency() # Fetching the raw frequencies for all the terms\n",
    "    post_list = postings_list() # Computing postings list for all the terms\n",
    "    term_idf = compute_idf(post_list) # Computing the idf scores for all the terms\n",
    "    for scheme in weight_schemes:\n",
    "        print(f'Computing weights for {scheme} scheme -> -> ->')\n",
    "        tf_idf[scheme] = {}\n",
    "        tf_idf[scheme] = np.zeros((len(proc_text), len(vocabulary))) # Declaring the numpy zeros array of dimensions (number of documents, number of terms in vocabulary)\n",
    "        for doc in tqdm(range(len(proc_text))):\n",
    "            for j in range(len(vocabulary)):\n",
    "                tf_weight = compute_tf_weight(scheme, vocabulary[j], rtf[doc]) # tf weight of term j in document i for the given scheme\n",
    "                idf = term_idf[vocabulary[j]] # idf score for term j\n",
    "                tf_idf[scheme][doc][j] = tf_weight * idf # Tf-idf score for term j in document i for given scheme\n",
    "    \n",
    "    return tf_idf\n",
    "\n",
    "# Preprocessing the query passed\n",
    "def query_preprocessing(text):\n",
    "    text = to_lower(text)  # Lower casing the text\n",
    "    text = tokenize(text)  # Tokenizing\n",
    "    text = remove_stopwords(text)  # Removing stop words\n",
    "    text = remove_punc(text)  # Removing punctuation marks\n",
    "    text = remove_blank(text)  # Removing blank spaces\n",
    "    return text\n",
    "\n",
    "# Computing the query vector for given query tokens\n",
    "def compute_query_vector(query_tokens):\n",
    "    query_vector = {}\n",
    "    query_tf = {} # Term frequencies for query tokens in document dataset\n",
    "    term_idf = compute_idf(postings_list()) # idf scores for terms\n",
    "    for term in query_tokens:\n",
    "        if term not in query_tf.keys():\n",
    "            query_tf[term] = 1\n",
    "        else:\n",
    "            query_tf[term] += 1\n",
    "    \n",
    "    print(query_tf)\n",
    "    for scheme in weight_schemes:\n",
    "        # Declaring query vector as numpy zeros of dimensions (length of vocabulary, 1)\n",
    "        query_vector[scheme] = np.zeros((len(vocabulary), 1)) \n",
    "        for i in range(len(vocabulary)):\n",
    "            tf_weight_ = compute_tf_weight(scheme, vocabulary[i], query_tf) # Assiging the required tf weight for ith vocabulary term\n",
    "            idf_ = term_idf[vocabulary[i]] if term in term_idf.keys() else 0\n",
    "            query_vector[scheme][i] = tf_weight_ * idf_ # Tf-idf score for qery token\n",
    "            \n",
    "    return query_vector\n",
    "\n",
    "# Generate results for the query passed for all weighting schemes and return top 5 documents for each\n",
    "def solve_tf_idf_query(query, tf_idf):\n",
    "    query_tokens = query_preprocessing(query) # Generating query tokens \n",
    "    query_vector = compute_query_vector(query_tokens) # Compute query vector for the processed query\n",
    "    print(query) \n",
    "    print(query_tokens)\n",
    "    print()\n",
    "    \n",
    "    for scheme in weight_schemes:\n",
    "        print(f\"Results for scheme : {scheme}\")\n",
    "        tf_mat = tf_idf[scheme] # Tf-idf matrix for the given scheme\n",
    "        query_vec = query_vector[scheme] # Getting the query vector for the given scheme\n",
    "        mult = np.dot(tf_mat, query_vec).reshape(len(proc_text)) # Getting the matrix multiplication for tf-idf matrix and query vector\n",
    "        ans = (-mult).argsort()[:5] # Getting the documents with top 5 scores\n",
    "        for ind in range(len(ans)):\n",
    "            print(doc_id_to_name[ans[ind]], end = \" \") # Priting the document names and scores for the best 5 documents\n",
    "        print()\n",
    "        vals = []\n",
    "        for idx in ans:\n",
    "            vals.append(mult[idx])\n",
    "        print(vals)\n",
    "        print()\n",
    "        print(\"----------------------\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3b8a5980",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                | 3/1400 [00:00<01:07, 20.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing weights for binary scheme -> -> ->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1400/1400 [00:52<00:00, 26.81it/s]\n",
      "  0%|▏                                                                                | 3/1400 [00:00<00:48, 29.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing weights for raw_count scheme -> -> ->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1400/1400 [00:52<00:00, 26.72it/s]\n",
      "  0%|▏                                                                                | 3/1400 [00:00<00:50, 27.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing weights for term_frequency scheme -> -> ->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1400/1400 [00:58<00:00, 24.03it/s]\n",
      "  0%|                                                                                 | 2/1400 [00:00<01:10, 19.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing weights for log_normal scheme -> -> ->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1400/1400 [00:51<00:00, 27.26it/s]\n",
      "  0%|▏                                                                                | 3/1400 [00:00<00:50, 27.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing weights for double_normal scheme -> -> ->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1400/1400 [00:53<00:00, 26.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# tf_idf = compute_tf_idf_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e96938b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for scheme in weight_schemes:\n",
    "#     pickle.dump(tf_idf[scheme], open(f\"../Q1/{scheme}_tf_idf.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fa02819",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = {}\n",
    "for scheme in weight_schemes:\n",
    "    tf_idf[scheme] = pickle.load(open(f\"../Q1/{scheme}_tf_idf.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4b1900a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(tf_idf['binary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b2131ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experimental': 1, 'design': 1, 'aerodynamic': 1, 'flows': 1}\n",
      "Experimental design of aerodynamic flows\n",
      "['experimental', 'design', 'aerodynamic', 'flows']\n",
      "\n",
      "Results for scheme : binary\n",
      "cranfield1285 cranfield0811 cranfield0518 cranfield0219 cranfield1088 \n",
      "[2.6956477391845755, 2.5680012843948976, 2.5680012843948976, 2.5680012843948976, 1.8352839030468309]\n",
      "\n",
      "----------------------\n",
      "\n",
      "Results for scheme : raw_count\n",
      "cranfield0094 cranfield0811 cranfield1386 cranfield1226 cranfield0721 \n",
      "[6.785037002184044, 5.136002568789795, 3.392518501092022, 3.392518501092022, 3.392518501092022]\n",
      "\n",
      "----------------------\n",
      "\n",
      "Results for scheme : term_frequency\n",
      "cranfield1285 cranfield0470 cranfield0389 cranfield0939 cranfield0460 \n",
      "[0.019254626708461252, 0.015145171879875099, 0.012472494489308903, 0.007853052085861161, 0.007439733555026364]\n",
      "\n",
      "----------------------\n",
      "\n",
      "Results for scheme : log_normal\n",
      "cranfield0811 cranfield0094 cranfield1285 cranfield1386 cranfield1226 \n",
      "[0.36883639860174133, 0.35691149893759483, 0.24427705960500878, 0.24363000005808041, 0.24363000005808041]\n",
      "\n",
      "----------------------\n",
      "\n",
      "Results for scheme : double_normal\n",
      "cranfield0718 cranfield0212 cranfield0645 cranfield1167 cranfield1061 \n",
      "[14176.27778042687, 14173.086161364681, 14165.82655871079, 14165.114292564469, 14164.626760843455]\n",
      "\n",
      "----------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "solve_tf_idf_query(\"Experimental design of aerodynamic flows\", tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a848892b",
   "metadata": {},
   "source": [
    "# Jacardian Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dccaad6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Intersection for query tokens and document tokens\n",
    "def intersection(query_tokens, doc_tokens):\n",
    "    return len(list(set(query_tokens) & set(doc_tokens)))\n",
    "\n",
    "# Union for query tokens and document tokens\n",
    "def union(query_tokens, doc_tokens):\n",
    "    return len(list(set(query_tokens) | set(doc_tokens)))\n",
    "\n",
    "# Gererating jacardian coefficient results for the given query\n",
    "def solve_jacardian_query(query):\n",
    "    query_tokens = query_preprocessing(query) # Getting query tokens\n",
    "    print(query_tokens)\n",
    "    print()\n",
    "    coeff = [0] * len(proc_text) # Jacardian Coefficient array for all the documents\n",
    "    for i in range(len(coeff)):\n",
    "        intersection_ = intersection(query_tokens, proc_text[doc_id_to_name[i]]) # Number of intersections for query tokens and document tokens\n",
    "        union_ = union(query_tokens, proc_text[doc_id_to_name[i]]) # Number of unions for query tokens and document tokens\n",
    "        coeff[i] =  intersection_ / union_ # Jacardian coefficient for given query and document dataset\n",
    "    coeff = np.array(coeff)\n",
    "    ans = (-coeff).argsort()[:5] # Getting the top 5 documents with highest scores\n",
    "    for ind in range(len(ans)): # Printing details of these 5 best documents\n",
    "        print(doc_id_to_name[ans[ind]], end = \" \")\n",
    "    print()\n",
    "    vals = []\n",
    "    for idx in ans:\n",
    "        vals.append(coeff[idx])\n",
    "    print(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca2c7e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['experimental', 'design', 'experimental', 'flows']\n",
      "\n",
      "cranfield1045 cranfield0418 cranfield0935 cranfield1069 cranfield0203 \n",
      "[0.06666666666666667, 0.0625, 0.0625, 0.06060606060606061, 0.05714285714285714]\n"
     ]
    }
   ],
   "source": [
    "solve_jacardian_query(\"Experimental design of experimental flows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09b0e8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 0 -> TF-IDF Query\n",
      "Enter 1 -> Jacardian Query\n",
      "0\n",
      "Enter Query\n",
      "experimental design for experimental flows\n",
      "{'experimental': 2, 'design': 1, 'flows': 1}\n",
      "experimental design for experimental flows\n",
      "['experimental', 'design', 'experimental', 'flows']\n",
      "\n",
      "Results for scheme : binary\n",
      "cranfield0811 cranfield0219 cranfield0518 cranfield1088 cranfield0560 \n",
      "[2.5680012843948976, 2.5680012843948976, 2.5680012843948976, 1.8352839030468309, 1.696259250546011]\n",
      "\n",
      "----------------------\n",
      "\n",
      "Results for scheme : raw_count\n",
      "cranfield0094 cranfield0811 cranfield1088 cranfield0562 cranfield1082 \n",
      "[6.785037002184044, 5.136002568789795, 3.6705678060936617, 3.392518501092022, 3.392518501092022]\n",
      "\n",
      "----------------------\n",
      "\n",
      "Results for scheme : term_frequency\n",
      "cranfield0470 cranfield0389 cranfield1088 cranfield0939 cranfield0460 \n",
      "[0.015145171879875099, 0.012472494489308903, 0.00812072523472049, 0.007853052085861161, 0.007439733555026364]\n",
      "\n",
      "----------------------\n",
      "\n",
      "Results for scheme : log_normal\n",
      "cranfield0811 cranfield0094 cranfield1088 cranfield0562 cranfield1082 \n",
      "[0.36883639860174133, 0.35691149893759483, 0.26359780632704943, 0.24363000005808041, 0.24363000005808041]\n",
      "\n",
      "----------------------\n",
      "\n",
      "Results for scheme : double_normal\n",
      "cranfield0718 cranfield0212 cranfield0645 cranfield1167 cranfield1061 \n",
      "[14175.070835925206, 14171.879216863017, 14164.619614209127, 14163.907348062807, 14163.419816341791]\n",
      "\n",
      "----------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Main function for running question 1\n",
    "def main():\n",
    "    print(\"Enter 0 -> TF-IDF Query\")\n",
    "    print(\"Enter 1 -> Jacardian Query\")\n",
    "    n = int(input())\n",
    "    print(\"Enter Query\")\n",
    "    query = str(input())\n",
    "    if query == \"\":\n",
    "        print(\"Empty query\")\n",
    "        return\n",
    "    if n == 0:\n",
    "        solve_tf_idf_query(query, tf_idf)\n",
    "    else:\n",
    "        solve_jacardian_query(query)\n",
    "\n",
    "main()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cee32d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
